{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook was motivated by\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "will be later cited as ResNetPaper\n",
    "Implementation: Oleh Bakumenko, Univerity of Duisburg-Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/datashare/MLCourse/Course_Materials\") # Preferentially import from the datashare.\n",
    "sys.path.append(\"../\") # Otherwise, import from the local folder's parent folder, where your stuff lives.\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "import torchvision, torchvision.transforms as tt\n",
    "from torch.multiprocessing import Manager\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data augmentation is a technique used to artificially increase the size of a dataset by transforming existing data points to create new, similar instances. This can help prevent overfitting in machine learning models, as well as improve their ability to generalize to unseen data. Common types of data augmentation include flipping, rotation, scaling, and adding noise to images.\n",
    "We can generate the augmentation list with torchvision.transforms module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augments = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.RandomHorizontalFlip(p = .5),\n",
    "    torchvision.transforms.RandomCrop((224, 224)), \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the dataset from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m         cache_mgr\u001B[38;5;241m.\u001B[39mdata[k] \u001B[38;5;241m=\u001B[39m cache_mgr\u001B[38;5;241m.\u001B[39mdict()\n\u001B[1;32m      8\u001B[0m         cache_mgr\u001B[38;5;241m.\u001B[39mcached[k] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43muu\u001B[49m\u001B[38;5;241m.\u001B[39mLiTS_Classification_Dataset(\n\u001B[1;32m     11\u001B[0m     data_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/coder/Course_Materials/data/Clean_LiTS/\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     transforms \u001B[38;5;241m=\u001B[39m data_augments,\n\u001B[1;32m     13\u001B[0m     verbose \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     14\u001B[0m     cache_data \u001B[38;5;241m=\u001B[39m cache_me,\n\u001B[1;32m     15\u001B[0m     cache_mgr \u001B[38;5;241m=\u001B[39m (cache_mgr \u001B[38;5;28;01mif\u001B[39;00m cache_me \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m     16\u001B[0m     debug \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     17\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'uu' is not defined"
     ]
    }
   ],
   "source": [
    "cache_me = False\n",
    "if cache_me is True:\n",
    "    cache_mgr = Manager()\n",
    "    cache_mgr.data = cache_mgr.dict()\n",
    "    cache_mgr.cached = cache_mgr.dict()\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        cache_mgr.data[k] = cache_mgr.dict()\n",
    "        cache_mgr.cached[k] = False\n",
    "\n",
    "ds = uu.LiTS_Classification_Dataset(\n",
    "    data_dir = \"/home/coder/Course_Materials/data/Clean_LiTS/\",\n",
    "    transforms = data_augments,\n",
    "    verbose = True,\n",
    "    cache_data = cache_me,\n",
    "    cache_mgr = (cache_mgr if cache_me is True else None),\n",
    "    debug = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 5e-5\n",
    "epochs = 15\n",
    "run_name = \"ResNet50\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "time_me  = True\n",
    "wantToPrint = False\n",
    "mod_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Dataloader\u001B[39;00m\n\u001B[1;32m      2\u001B[0m dl \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\n\u001B[0;32m----> 3\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m, \n\u001B[1;32m      4\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m batch_size, \n\u001B[1;32m      5\u001B[0m     num_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m, \n\u001B[1;32m      6\u001B[0m     shuffle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \n\u001B[1;32m      7\u001B[0m     drop_last \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, \n\u001B[1;32m      8\u001B[0m     pin_memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m     persistent_workers \u001B[38;5;241m=\u001B[39m (\u001B[38;5;129;01mnot\u001B[39;00m cache_me),\n\u001B[1;32m     10\u001B[0m     prefetch_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     11\u001B[0m     )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset = ds, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = 4, \n",
    "    shuffle = True, \n",
    "    drop_last = False, \n",
    "    pin_memory = True,\n",
    "    persistent_workers = (not cache_me),\n",
    "    prefetch_factor = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ResNet (Residual Network) is a deep neural network architecture introduced in 2015, designed to address the issue of vanishing gradients in very deep networks. It's named ResNet because it uses residual connections (skip connections), which allow for the flow of gradients from earlier layers to later layers even in very deep networks.\n",
    "\n",
    "The residual connections in ResNet consist of adding the input of a layer to the output of a layer several layers deeper, allowing the network to more easily learn identity functions. This design helps prevent the issue of vanishing gradients and allows ResNet to train much deeper networks than previously possible.\n",
    "This architecture showed very high benchmarks in the seminar in comparison to earlier AlexNet model\n",
    "\n",
    "Original ResNet was used in the ImageNet Challenge to classify 1000 classes, we use only 3 in our exercise:\n",
    "\t\t0: Image does not include liver\n",
    "\t\t1: Liver is visible\n",
    "\t\t2: Liver is visible and lesion is visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "num_params = torch.zeros(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0.])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet18"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class ResBlockDimsReduction(nn.Module):\n",
    "    def __init__(self, n_chans_in, n_chans_out):\n",
    "        super(ResBlockDimsReduction, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans_in, n_chans_out, kernel_size=3, stride=2,padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans_out, n_chans_out, kernel_size=3,padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans_out)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(n_chans_in, n_chans_out, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(num_features=n_chans_out)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        if (x.shape[1] != out.shape[1]):\n",
    "            x = self.downsample(x)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class ResNetMLMed18(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.resblocks2 =nn.Sequential(\n",
    "            *(2 * [ResBlock(n_chans=64)]))\n",
    "        self.resblocks3 = nn.Sequential(ResBlockDimsReduction(n_chans_in=64,n_chans_out=128),\n",
    "            *(1 * [ResBlock(n_chans=128)]))\n",
    "        self.resblocks4 = nn.Sequential(ResBlockDimsReduction(n_chans_in=128,n_chans_out=256),\n",
    "            *(1 * [ResBlock(n_chans=256)]))\n",
    "        self.resblocks5 = nn.Sequential(ResBlockDimsReduction(n_chans_in=256,n_chans_out=512),\n",
    "            *(1 * [ResBlock(n_chans=512)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=512, out_features=3, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4 = self.resblocks4(out_3)\n",
    "\n",
    "        out_5 = self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "\n",
    "        return out_6\n",
    "\n",
    "    pass\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 110, 110]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 110, 110]             128\n",
      "              ReLU-3         [-1, 64, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 64, 54, 54]               0\n",
      "            Conv2d-5           [-1, 64, 54, 54]          36,928\n",
      "       BatchNorm2d-6           [-1, 64, 54, 54]             128\n",
      "              ReLU-7           [-1, 64, 54, 54]               0\n",
      "            Conv2d-8           [-1, 64, 54, 54]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 54, 54]             128\n",
      "         ResBlock-10           [-1, 64, 54, 54]               0\n",
      "           Conv2d-11           [-1, 64, 54, 54]          36,928\n",
      "      BatchNorm2d-12           [-1, 64, 54, 54]             128\n",
      "             ReLU-13           [-1, 64, 54, 54]               0\n",
      "           Conv2d-14           [-1, 64, 54, 54]          36,928\n",
      "      BatchNorm2d-15           [-1, 64, 54, 54]             128\n",
      "         ResBlock-16           [-1, 64, 54, 54]               0\n",
      "           Conv2d-17          [-1, 128, 27, 27]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 27, 27]             256\n",
      "             ReLU-19          [-1, 128, 27, 27]               0\n",
      "           Conv2d-20          [-1, 128, 27, 27]         147,584\n",
      "      BatchNorm2d-21          [-1, 128, 27, 27]             256\n",
      "           Conv2d-22          [-1, 128, 27, 27]           8,320\n",
      "      BatchNorm2d-23          [-1, 128, 27, 27]             256\n",
      "ResBlockDimsReduction-24          [-1, 128, 27, 27]               0\n",
      "           Conv2d-25          [-1, 128, 27, 27]         147,584\n",
      "      BatchNorm2d-26          [-1, 128, 27, 27]             256\n",
      "             ReLU-27          [-1, 128, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]         147,584\n",
      "      BatchNorm2d-29          [-1, 128, 27, 27]             256\n",
      "         ResBlock-30          [-1, 128, 27, 27]               0\n",
      "           Conv2d-31          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-32          [-1, 256, 14, 14]             512\n",
      "             ReLU-33          [-1, 256, 14, 14]               0\n",
      "           Conv2d-34          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-35          [-1, 256, 14, 14]             512\n",
      "           Conv2d-36          [-1, 256, 14, 14]          33,024\n",
      "      BatchNorm2d-37          [-1, 256, 14, 14]             512\n",
      "ResBlockDimsReduction-38          [-1, 256, 14, 14]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "         ResBlock-44          [-1, 256, 14, 14]               0\n",
      "           Conv2d-45            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-46            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-47            [-1, 512, 7, 7]               0\n",
      "           Conv2d-48            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-49            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-50            [-1, 512, 7, 7]         131,584\n",
      "      BatchNorm2d-51            [-1, 512, 7, 7]           1,024\n",
      "ResBlockDimsReduction-52            [-1, 512, 7, 7]               0\n",
      "           Conv2d-53            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-54            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-55            [-1, 512, 7, 7]               0\n",
      "           Conv2d-56            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "         ResBlock-58            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-59            [-1, 512, 1, 1]               0\n",
      "           Linear-60                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 11,176,579\n",
      "Trainable params: 11,176,579\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 54.24\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 97.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed18()\n",
    "summary(model, (1, 224, 224))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "num_params[0] = 11176579"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ResNet 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is strongly recommended to parallel look into Table 1 (page 5) and Figure 5 (page 6), ResNetPaper,\n",
    "\n",
    "Implementing the normal ResNet Block = [conv -> batch_norm -> activation] *2\n",
    "\n",
    "At the beginnig of each new layer (in the Table 1, left) the image size will be reduced using convolution with kernel 1 and a stride of 2 (so-called projection), this feature was generalised in the implemention of ResNet 50 below. As an example it was decided to include both variations.\n",
    "\n",
    "First we start with building the blocks. Note the downsampling operation in the ResBlockDimsReduction, because the input image $x$ has different dimentions that the output. If this is not clear, try print(out.shape).\n",
    "\n",
    "Class ResNetMLMed34 will inherit the torch.nn.module, so we need to write the init() and forward() functions. Using the Table 1 and Figure 5 form ResNetPaper we define each resblocks2-5 part, the indexing is the same as in Table 1 so the one can compare number blocks, kernel sizes and number channels.\n",
    "Do not forget to put downsampling block as the first in each resblocks2-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Couple words about torch.nn.init. part:\n",
    "Pytorch initialise the parameters for Conv and batch norm randomly. Initialization of the weights and biases in a normal distribution helps the model backtrack gradients in early epoch's.\n",
    "For smaller models like 34 and 50 layer it was tested, that initialization of the weights and biases has almost no impact on performance or convergence of the model.\n",
    "\n",
    "For ResNet 152 on the other had, random initialised model did not converge after 15 epochs and showed very bad error and accuracy rates. With initialization, it still was not great, but may could be tuned by the hyperparameters and better optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResBlock Class\n",
    "#       - constructs a block [conv -> batch_norm -> activation] *2, which we will stack in the network\n",
    "# Input:    int: n_chans - number channels\n",
    "# Output:   nn.Sequential() block\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias= False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias= False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        return out + x # this sum realise the skip connection\n",
    "\n",
    "\n",
    "# ResBlockDimsReduction Class\n",
    "#       - constructs a first block in the layer\n",
    "#       - [conv -> batch_norm -> activation] *2\n",
    "#       - downsampling performed with stride 2\n",
    "# Input:    int: n_chans_in; int:n_chans_out\n",
    "# Output:   nn.Sequential() block\n",
    "\n",
    "class ResBlockDimsReduction(nn.Module):\n",
    "    def __init__(self, n_chans_in, n_chans_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans_in, n_chans_out, kernel_size=3, stride=2,padding=1,bias= False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans_out, n_chans_out, kernel_size=3, padding=1, bias= False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans_out)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(n_chans_in, n_chans_out, kernel_size=1, stride=2,bias= False),\n",
    "            nn.BatchNorm2d(num_features=n_chans_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        # input and output dimensions not match, so we need to project x into the dimensions of out\n",
    "        x = self.downsample(x)\n",
    "        return out + x\n",
    "\n",
    "# ResNetMLMed34 Class\n",
    "#       - constructs a ResNet34 as described above.\n",
    "# Input:    Tensor: [Batch,1,Height,Width]\n",
    "# Output:   Tensor: [Batch,3]\n",
    "class ResNetMLMed34(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1, bias= False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.resblocks2 =nn.Sequential(\n",
    "            *(3 * [ResBlock(n_chans=64)]))\n",
    "        self.resblocks3 = nn.Sequential(ResBlockDimsReduction(n_chans_in=64,n_chans_out=128),\n",
    "            *(3 * [ResBlock(n_chans=128)]))\n",
    "        self.resblocks4 = nn.Sequential(ResBlockDimsReduction(n_chans_in=128,n_chans_out=256),\n",
    "            *(5 * [ResBlock(n_chans=256)]))\n",
    "        self.resblocks5 = nn.Sequential(ResBlockDimsReduction(n_chans_in=256,n_chans_out=512),\n",
    "            *(2 * [ResBlock(n_chans=512)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=512, out_features=3, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4 = self.resblocks4(out_3)\n",
    "\n",
    "        out_5 = self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "\n",
    "        return out_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 110, 110]           3,136\n",
      "       BatchNorm2d-2         [-1, 64, 110, 110]             128\n",
      "              ReLU-3         [-1, 64, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 64, 54, 54]               0\n",
      "            Conv2d-5           [-1, 64, 54, 54]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 54, 54]             128\n",
      "              ReLU-7           [-1, 64, 54, 54]               0\n",
      "            Conv2d-8           [-1, 64, 54, 54]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 54, 54]             128\n",
      "             ReLU-10           [-1, 64, 54, 54]               0\n",
      "         ResBlock-11           [-1, 64, 54, 54]               0\n",
      "           Conv2d-12           [-1, 64, 54, 54]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 54, 54]             128\n",
      "             ReLU-14           [-1, 64, 54, 54]               0\n",
      "           Conv2d-15           [-1, 64, 54, 54]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 54, 54]             128\n",
      "             ReLU-17           [-1, 64, 54, 54]               0\n",
      "         ResBlock-18           [-1, 64, 54, 54]               0\n",
      "           Conv2d-19           [-1, 64, 54, 54]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 54, 54]             128\n",
      "             ReLU-21           [-1, 64, 54, 54]               0\n",
      "           Conv2d-22           [-1, 64, 54, 54]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 54, 54]             128\n",
      "             ReLU-24           [-1, 64, 54, 54]               0\n",
      "         ResBlock-25           [-1, 64, 54, 54]               0\n",
      "           Conv2d-26          [-1, 128, 27, 27]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 27, 27]             256\n",
      "             ReLU-28          [-1, 128, 27, 27]               0\n",
      "           Conv2d-29          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 27, 27]             256\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "           Conv2d-32          [-1, 128, 27, 27]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 27, 27]             256\n",
      "             ReLU-34          [-1, 128, 27, 27]               0\n",
      "ResBlockDimsReduction-35          [-1, 128, 27, 27]               0\n",
      "           Conv2d-36          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-37          [-1, 128, 27, 27]             256\n",
      "             ReLU-38          [-1, 128, 27, 27]               0\n",
      "           Conv2d-39          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 27, 27]             256\n",
      "             ReLU-41          [-1, 128, 27, 27]               0\n",
      "         ResBlock-42          [-1, 128, 27, 27]               0\n",
      "           Conv2d-43          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 27, 27]             256\n",
      "             ReLU-45          [-1, 128, 27, 27]               0\n",
      "           Conv2d-46          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 27, 27]             256\n",
      "             ReLU-48          [-1, 128, 27, 27]               0\n",
      "         ResBlock-49          [-1, 128, 27, 27]               0\n",
      "           Conv2d-50          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 27, 27]             256\n",
      "             ReLU-52          [-1, 128, 27, 27]               0\n",
      "           Conv2d-53          [-1, 128, 27, 27]         147,456\n",
      "      BatchNorm2d-54          [-1, 128, 27, 27]             256\n",
      "             ReLU-55          [-1, 128, 27, 27]               0\n",
      "         ResBlock-56          [-1, 128, 27, 27]               0\n",
      "           Conv2d-57          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-58          [-1, 256, 14, 14]             512\n",
      "             ReLU-59          [-1, 256, 14, 14]               0\n",
      "           Conv2d-60          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 14, 14]             512\n",
      "             ReLU-62          [-1, 256, 14, 14]               0\n",
      "           Conv2d-63          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-64          [-1, 256, 14, 14]             512\n",
      "             ReLU-65          [-1, 256, 14, 14]               0\n",
      "ResBlockDimsReduction-66          [-1, 256, 14, 14]               0\n",
      "           Conv2d-67          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-68          [-1, 256, 14, 14]             512\n",
      "             ReLU-69          [-1, 256, 14, 14]               0\n",
      "           Conv2d-70          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-71          [-1, 256, 14, 14]             512\n",
      "             ReLU-72          [-1, 256, 14, 14]               0\n",
      "         ResBlock-73          [-1, 256, 14, 14]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "             ReLU-76          [-1, 256, 14, 14]               0\n",
      "           Conv2d-77          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-78          [-1, 256, 14, 14]             512\n",
      "             ReLU-79          [-1, 256, 14, 14]               0\n",
      "         ResBlock-80          [-1, 256, 14, 14]               0\n",
      "           Conv2d-81          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
      "             ReLU-83          [-1, 256, 14, 14]               0\n",
      "           Conv2d-84          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "             ReLU-86          [-1, 256, 14, 14]               0\n",
      "         ResBlock-87          [-1, 256, 14, 14]               0\n",
      "           Conv2d-88          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-89          [-1, 256, 14, 14]             512\n",
      "             ReLU-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "         ResBlock-94          [-1, 256, 14, 14]               0\n",
      "           Conv2d-95          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-96          [-1, 256, 14, 14]             512\n",
      "             ReLU-97          [-1, 256, 14, 14]               0\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "            ReLU-100          [-1, 256, 14, 14]               0\n",
      "        ResBlock-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-103            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-104            [-1, 512, 7, 7]               0\n",
      "          Conv2d-105            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "          Conv2d-108            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-109            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "ResBlockDimsReduction-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "          Conv2d-115            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-116            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-117            [-1, 512, 7, 7]               0\n",
      "        ResBlock-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "          Conv2d-122            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-123            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-124            [-1, 512, 7, 7]               0\n",
      "        ResBlock-125            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-126            [-1, 512, 1, 1]               0\n",
      "          Linear-127                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 21,279,939\n",
      "Trainable params: 21,279,939\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 92.94\n",
      "Params size (MB): 81.18\n",
      "Estimated Total Size (MB): 174.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed34()\n",
    "summary(model, (1, 224, 224))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "num_params[1] = 21279939"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ResNet50 introduced a new structure - the bottleneck block = [conv -> batch_norm -> activation]*3, where besides the 3 * 3 convolution we also oscillate the number of channels in each block with the 1 * 1 convolution.\n",
    "For more tuning opportunities, the variables number channels in, between and out are given to the block, mostly in channels will be the same as out channels.\n",
    "\n",
    "A generalized solution for the downsampling issue is used: instead of 2 different blocks in ResNet34 we define the boolean variable and a stride for this purpose. If the want to downsample at the beginning of the resblocks3-5, we set downsample=True, stride=2. Note that there is no need to change the stride in the second resblocks2 part.\n",
    "If downsample is not needed, this operation will be set to nn.Identity()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResBlockBottleneck Class\n",
    "#       - constructs a block [conv -> batch_norm -> activation]*3, which we will stack in the network\n",
    "# Input:    int: n_chans_in, int:n_chans_between, int:n_chans_out\n",
    "#           boolean: downsample = False, set True if first block\n",
    "#           int: stride = 1, set 2 if want to downsample\n",
    "# Output:   nn.Sequential() block\n",
    "class ResBlockBottleneck(nn.Module):\n",
    "    def __init__(self, n_chans_in,n_chans_between,n_chans_out, downsample = False, stride = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans_in, n_chans_between, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans_between, n_chans_between, kernel_size=3, stride= stride, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(n_chans_between, n_chans_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(num_features=n_chans_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv3.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm3.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm3.bias)\n",
    "\n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(n_chans_in, n_chans_out, kernel_size=1,padding=0,stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=n_chans_out),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.relu(out)\n",
    "        return out + self.downsample(x)\n",
    "\n",
    "# ResNetMLMed50 Class\n",
    "#       - constructs a ResNet50 as described above.\n",
    "# Input:    Tensor: [Batch,1,Height,Width]\n",
    "# Output:   Tensor: [Batch,3]\n",
    "class ResNetMLMed50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2,padding=1)\n",
    "        self.resblocks2 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 64,n_chans_between =64 ,n_chans_out=256,downsample= True),\n",
    "            *(2 * [ResBlockBottleneck(n_chans_in = 256,n_chans_between=64,n_chans_out= 256)]))\n",
    "        self.resblocks3 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 256, n_chans_between=128, n_chans_out= 512, downsample=True, stride=2),\n",
    "            *(3 * [ResBlockBottleneck(n_chans_in = 512,n_chans_between=128,n_chans_out= 512)]))\n",
    "        self.resblocks4 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 512, n_chans_between=256, n_chans_out= 1024,downsample=True, stride=2),\n",
    "            *(5 * [ResBlockBottleneck(n_chans_in = 1024,n_chans_between=256,n_chans_out= 1024)]))\n",
    "        self.resblocks5 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 1024, n_chans_between=512, n_chans_out= 2048,downsample=True, stride=2),\n",
    "            *(2 * [ResBlockBottleneck(n_chans_in = 2048,n_chans_between=512,n_chans_out= 2048)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=2048, out_features=3, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4= self.resblocks4(out_3)\n",
    "\n",
    "        out_5= self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "        return out_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 110, 110]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 110, 110]             128\n",
      "              ReLU-3         [-1, 64, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 64, 55, 55]               0\n",
      "            Conv2d-5           [-1, 64, 55, 55]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 55, 55]             128\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 55, 55]             128\n",
      "             ReLU-10           [-1, 64, 55, 55]               0\n",
      "           Conv2d-11          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 55, 55]             512\n",
      "             ReLU-13          [-1, 256, 55, 55]               0\n",
      "           Conv2d-14          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 55, 55]             512\n",
      "             ReLU-16          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-17          [-1, 256, 55, 55]               0\n",
      "           Conv2d-18           [-1, 64, 55, 55]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 55, 55]             128\n",
      "             ReLU-20           [-1, 64, 55, 55]               0\n",
      "           Conv2d-21           [-1, 64, 55, 55]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 55, 55]             128\n",
      "             ReLU-23           [-1, 64, 55, 55]               0\n",
      "           Conv2d-24          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 55, 55]             512\n",
      "             ReLU-26          [-1, 256, 55, 55]               0\n",
      "         Identity-27          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-28          [-1, 256, 55, 55]               0\n",
      "           Conv2d-29           [-1, 64, 55, 55]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 55, 55]             128\n",
      "             ReLU-31           [-1, 64, 55, 55]               0\n",
      "           Conv2d-32           [-1, 64, 55, 55]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 55, 55]             128\n",
      "             ReLU-34           [-1, 64, 55, 55]               0\n",
      "           Conv2d-35          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 55, 55]             512\n",
      "             ReLU-37          [-1, 256, 55, 55]               0\n",
      "         Identity-38          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-39          [-1, 256, 55, 55]               0\n",
      "           Conv2d-40          [-1, 128, 55, 55]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 55, 55]             256\n",
      "             ReLU-42          [-1, 128, 55, 55]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "         Identity-62          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "         Identity-73          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "         Identity-84          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "           Conv2d-92         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-93         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-96         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-97         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-98         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-103          [-1, 256, 14, 14]             512\n",
      "            ReLU-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-106         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-107         [-1, 1024, 14, 14]               0\n",
      "        Identity-108         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-109         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "            ReLU-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 14, 14]             512\n",
      "            ReLU-115          [-1, 256, 14, 14]               0\n",
      "          Conv2d-116         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-117         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-118         [-1, 1024, 14, 14]               0\n",
      "        Identity-119         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "        Identity-130         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-131         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-132          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-133          [-1, 256, 14, 14]             512\n",
      "            ReLU-134          [-1, 256, 14, 14]               0\n",
      "          Conv2d-135          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-136          [-1, 256, 14, 14]             512\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-139         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-140         [-1, 1024, 14, 14]               0\n",
      "        Identity-141         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "        Identity-152         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-155          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-156          [-1, 512, 14, 14]               0\n",
      "          Conv2d-157            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-158            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-159            [-1, 512, 7, 7]               0\n",
      "          Conv2d-160           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-161           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-165           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-166           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-167            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-168            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-169            [-1, 512, 7, 7]               0\n",
      "          Conv2d-170            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-172            [-1, 512, 7, 7]               0\n",
      "          Conv2d-173           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-174           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-175           [-1, 2048, 7, 7]               0\n",
      "        Identity-176           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-177           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-178            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-179            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-180            [-1, 512, 7, 7]               0\n",
      "          Conv2d-181            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-182            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-183            [-1, 512, 7, 7]               0\n",
      "          Conv2d-184           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-185           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-186           [-1, 2048, 7, 7]               0\n",
      "        Identity-187           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-188           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-189           [-1, 2048, 1, 1]               0\n",
      "          Linear-190                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 23,507,971\n",
      "Trainable params: 23,507,971\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 322.97\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 412.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed50()\n",
    "summary(model, (1, 224, 224))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "num_params[2] = 23507971"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ResNet 152\n",
    "\n",
    "The same as ResNet 50 but with more blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResNetMLMed152(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMLMed152, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2,padding=1)\n",
    "        self.resblocks2 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 64,n_chans_between =64 ,n_chans_out=256,downsample= True),\n",
    "            *(2 * [ResBlockBottleneck(n_chans_in = 256,n_chans_between=64,n_chans_out= 256)]))\n",
    "        self.resblocks3 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 256, n_chans_between=128, n_chans_out= 512, downsample=True, stride=2),\n",
    "            *(7 * [ResBlockBottleneck(n_chans_in = 512,n_chans_between=128,n_chans_out= 512)]))\n",
    "        self.resblocks4 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 512, n_chans_between=256, n_chans_out= 1024,downsample=True, stride=2),\n",
    "            *(35 * [ResBlockBottleneck(n_chans_in = 1024,n_chans_between=256,n_chans_out= 1024)]))\n",
    "        self.resblocks5 = nn.Sequential(\n",
    "            ResBlockBottleneck(n_chans_in = 1024, n_chans_between=512, n_chans_out= 2048,downsample=True, stride=2),\n",
    "            *(2 * [ResBlockBottleneck(n_chans_in = 2048,n_chans_between=512,n_chans_out= 2048)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=2048, out_features=3, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4= self.resblocks4(out_3)\n",
    "\n",
    "        out_5= self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "\n",
    "        return out_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 110, 110]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 110, 110]             128\n",
      "              ReLU-3         [-1, 64, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 64, 55, 55]               0\n",
      "            Conv2d-5           [-1, 64, 55, 55]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 55, 55]             128\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 55, 55]             128\n",
      "             ReLU-10           [-1, 64, 55, 55]               0\n",
      "           Conv2d-11          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 55, 55]             512\n",
      "             ReLU-13          [-1, 256, 55, 55]               0\n",
      "           Conv2d-14          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 55, 55]             512\n",
      "             ReLU-16          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-17          [-1, 256, 55, 55]               0\n",
      "           Conv2d-18           [-1, 64, 55, 55]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 55, 55]             128\n",
      "             ReLU-20           [-1, 64, 55, 55]               0\n",
      "           Conv2d-21           [-1, 64, 55, 55]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 55, 55]             128\n",
      "             ReLU-23           [-1, 64, 55, 55]               0\n",
      "           Conv2d-24          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 55, 55]             512\n",
      "             ReLU-26          [-1, 256, 55, 55]               0\n",
      "         Identity-27          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-28          [-1, 256, 55, 55]               0\n",
      "           Conv2d-29           [-1, 64, 55, 55]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 55, 55]             128\n",
      "             ReLU-31           [-1, 64, 55, 55]               0\n",
      "           Conv2d-32           [-1, 64, 55, 55]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 55, 55]             128\n",
      "             ReLU-34           [-1, 64, 55, 55]               0\n",
      "           Conv2d-35          [-1, 256, 55, 55]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 55, 55]             512\n",
      "             ReLU-37          [-1, 256, 55, 55]               0\n",
      "         Identity-38          [-1, 256, 55, 55]               0\n",
      "ResBlockBottleneck-39          [-1, 256, 55, 55]               0\n",
      "           Conv2d-40          [-1, 128, 55, 55]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 55, 55]             256\n",
      "             ReLU-42          [-1, 128, 55, 55]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "         Identity-62          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "         Identity-73          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "         Identity-84          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-87          [-1, 128, 28, 28]             256\n",
      "             ReLU-88          [-1, 128, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-93          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-94          [-1, 512, 28, 28]               0\n",
      "         Identity-95          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-96          [-1, 512, 28, 28]               0\n",
      "           Conv2d-97          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-98          [-1, 128, 28, 28]             256\n",
      "             ReLU-99          [-1, 128, 28, 28]               0\n",
      "          Conv2d-100          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-101          [-1, 128, 28, 28]             256\n",
      "            ReLU-102          [-1, 128, 28, 28]               0\n",
      "          Conv2d-103          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-104          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-105          [-1, 512, 28, 28]               0\n",
      "        Identity-106          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-107          [-1, 512, 28, 28]               0\n",
      "          Conv2d-108          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-109          [-1, 128, 28, 28]             256\n",
      "            ReLU-110          [-1, 128, 28, 28]               0\n",
      "          Conv2d-111          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-112          [-1, 128, 28, 28]             256\n",
      "            ReLU-113          [-1, 128, 28, 28]               0\n",
      "          Conv2d-114          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-115          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-116          [-1, 512, 28, 28]               0\n",
      "        Identity-117          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-120          [-1, 128, 28, 28]             256\n",
      "            ReLU-121          [-1, 128, 28, 28]               0\n",
      "          Conv2d-122          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-123          [-1, 128, 28, 28]             256\n",
      "            ReLU-124          [-1, 128, 28, 28]               0\n",
      "          Conv2d-125          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-126          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-127          [-1, 512, 28, 28]               0\n",
      "        Identity-128          [-1, 512, 28, 28]               0\n",
      "ResBlockBottleneck-129          [-1, 512, 28, 28]               0\n",
      "          Conv2d-130          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-131          [-1, 256, 28, 28]             512\n",
      "            ReLU-132          [-1, 256, 28, 28]               0\n",
      "          Conv2d-133          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-134          [-1, 256, 14, 14]             512\n",
      "            ReLU-135          [-1, 256, 14, 14]               0\n",
      "          Conv2d-136         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-137         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-138         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-139         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-140         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-141         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "        Identity-152         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 14, 14]             512\n",
      "            ReLU-159          [-1, 256, 14, 14]               0\n",
      "          Conv2d-160         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-162         [-1, 1024, 14, 14]               0\n",
      "        Identity-163         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-164         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-165          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-166          [-1, 256, 14, 14]             512\n",
      "            ReLU-167          [-1, 256, 14, 14]               0\n",
      "          Conv2d-168          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-169          [-1, 256, 14, 14]             512\n",
      "            ReLU-170          [-1, 256, 14, 14]               0\n",
      "          Conv2d-171         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-172         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-173         [-1, 1024, 14, 14]               0\n",
      "        Identity-174         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-175         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-176          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 14, 14]             512\n",
      "            ReLU-178          [-1, 256, 14, 14]               0\n",
      "          Conv2d-179          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 14, 14]             512\n",
      "            ReLU-181          [-1, 256, 14, 14]               0\n",
      "          Conv2d-182         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-184         [-1, 1024, 14, 14]               0\n",
      "        Identity-185         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-186         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-187          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 14, 14]             512\n",
      "            ReLU-189          [-1, 256, 14, 14]               0\n",
      "          Conv2d-190          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 14, 14]             512\n",
      "            ReLU-192          [-1, 256, 14, 14]               0\n",
      "          Conv2d-193         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-195         [-1, 1024, 14, 14]               0\n",
      "        Identity-196         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-197         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-198          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 14, 14]             512\n",
      "            ReLU-200          [-1, 256, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-205         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-206         [-1, 1024, 14, 14]               0\n",
      "        Identity-207         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-208         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-209          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-210          [-1, 256, 14, 14]             512\n",
      "            ReLU-211          [-1, 256, 14, 14]               0\n",
      "          Conv2d-212          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-213          [-1, 256, 14, 14]             512\n",
      "            ReLU-214          [-1, 256, 14, 14]               0\n",
      "          Conv2d-215         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-216         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-217         [-1, 1024, 14, 14]               0\n",
      "        Identity-218         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-219         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-220          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 14, 14]             512\n",
      "            ReLU-222          [-1, 256, 14, 14]               0\n",
      "          Conv2d-223          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 14, 14]             512\n",
      "            ReLU-225          [-1, 256, 14, 14]               0\n",
      "          Conv2d-226         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-228         [-1, 1024, 14, 14]               0\n",
      "        Identity-229         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "        Identity-240         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-241         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-242          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-243          [-1, 256, 14, 14]             512\n",
      "            ReLU-244          [-1, 256, 14, 14]               0\n",
      "          Conv2d-245          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 14, 14]             512\n",
      "            ReLU-247          [-1, 256, 14, 14]               0\n",
      "          Conv2d-248         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-249         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-250         [-1, 1024, 14, 14]               0\n",
      "        Identity-251         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-252         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-253          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-254          [-1, 256, 14, 14]             512\n",
      "            ReLU-255          [-1, 256, 14, 14]               0\n",
      "          Conv2d-256          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-257          [-1, 256, 14, 14]             512\n",
      "            ReLU-258          [-1, 256, 14, 14]               0\n",
      "          Conv2d-259         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-260         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-261         [-1, 1024, 14, 14]               0\n",
      "        Identity-262         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-263         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-268          [-1, 256, 14, 14]             512\n",
      "            ReLU-269          [-1, 256, 14, 14]               0\n",
      "          Conv2d-270         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-271         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-272         [-1, 1024, 14, 14]               0\n",
      "        Identity-273         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-274         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-275          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-276          [-1, 256, 14, 14]             512\n",
      "            ReLU-277          [-1, 256, 14, 14]               0\n",
      "          Conv2d-278          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-279          [-1, 256, 14, 14]             512\n",
      "            ReLU-280          [-1, 256, 14, 14]               0\n",
      "          Conv2d-281         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-282         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-283         [-1, 1024, 14, 14]               0\n",
      "        Identity-284         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-285         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-286          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-287          [-1, 256, 14, 14]             512\n",
      "            ReLU-288          [-1, 256, 14, 14]               0\n",
      "          Conv2d-289          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-290          [-1, 256, 14, 14]             512\n",
      "            ReLU-291          [-1, 256, 14, 14]               0\n",
      "          Conv2d-292         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-293         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-294         [-1, 1024, 14, 14]               0\n",
      "        Identity-295         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-296         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-297          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-298          [-1, 256, 14, 14]             512\n",
      "            ReLU-299          [-1, 256, 14, 14]               0\n",
      "          Conv2d-300          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-301          [-1, 256, 14, 14]             512\n",
      "            ReLU-302          [-1, 256, 14, 14]               0\n",
      "          Conv2d-303         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-304         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-305         [-1, 1024, 14, 14]               0\n",
      "        Identity-306         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-307         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-308          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-309          [-1, 256, 14, 14]             512\n",
      "            ReLU-310          [-1, 256, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-316         [-1, 1024, 14, 14]               0\n",
      "        Identity-317         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-318         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-319          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-320          [-1, 256, 14, 14]             512\n",
      "            ReLU-321          [-1, 256, 14, 14]               0\n",
      "          Conv2d-322          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-323          [-1, 256, 14, 14]             512\n",
      "            ReLU-324          [-1, 256, 14, 14]               0\n",
      "          Conv2d-325         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-326         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-327         [-1, 1024, 14, 14]               0\n",
      "        Identity-328         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-329         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-330          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-331          [-1, 256, 14, 14]             512\n",
      "            ReLU-332          [-1, 256, 14, 14]               0\n",
      "          Conv2d-333          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-334          [-1, 256, 14, 14]             512\n",
      "            ReLU-335          [-1, 256, 14, 14]               0\n",
      "          Conv2d-336         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-337         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-338         [-1, 1024, 14, 14]               0\n",
      "        Identity-339         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "        Identity-350         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-351         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-352          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-353          [-1, 256, 14, 14]             512\n",
      "            ReLU-354          [-1, 256, 14, 14]               0\n",
      "          Conv2d-355          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-356          [-1, 256, 14, 14]             512\n",
      "            ReLU-357          [-1, 256, 14, 14]               0\n",
      "          Conv2d-358         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-359         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-360         [-1, 1024, 14, 14]               0\n",
      "        Identity-361         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-362         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-363          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-364          [-1, 256, 14, 14]             512\n",
      "            ReLU-365          [-1, 256, 14, 14]               0\n",
      "          Conv2d-366          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-367          [-1, 256, 14, 14]             512\n",
      "            ReLU-368          [-1, 256, 14, 14]               0\n",
      "          Conv2d-369         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-370         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-371         [-1, 1024, 14, 14]               0\n",
      "        Identity-372         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-373         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-378          [-1, 256, 14, 14]             512\n",
      "            ReLU-379          [-1, 256, 14, 14]               0\n",
      "          Conv2d-380         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-381         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-382         [-1, 1024, 14, 14]               0\n",
      "        Identity-383         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-384         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-385          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-386          [-1, 256, 14, 14]             512\n",
      "            ReLU-387          [-1, 256, 14, 14]               0\n",
      "          Conv2d-388          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-389          [-1, 256, 14, 14]             512\n",
      "            ReLU-390          [-1, 256, 14, 14]               0\n",
      "          Conv2d-391         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-392         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-393         [-1, 1024, 14, 14]               0\n",
      "        Identity-394         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-395         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-396          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-397          [-1, 256, 14, 14]             512\n",
      "            ReLU-398          [-1, 256, 14, 14]               0\n",
      "          Conv2d-399          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-400          [-1, 256, 14, 14]             512\n",
      "            ReLU-401          [-1, 256, 14, 14]               0\n",
      "          Conv2d-402         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-403         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-404         [-1, 1024, 14, 14]               0\n",
      "        Identity-405         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-406         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-407          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-408          [-1, 256, 14, 14]             512\n",
      "            ReLU-409          [-1, 256, 14, 14]               0\n",
      "          Conv2d-410          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-411          [-1, 256, 14, 14]             512\n",
      "            ReLU-412          [-1, 256, 14, 14]               0\n",
      "          Conv2d-413         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-414         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-415         [-1, 1024, 14, 14]               0\n",
      "        Identity-416         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-417         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-418          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-419          [-1, 256, 14, 14]             512\n",
      "            ReLU-420          [-1, 256, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-425         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-426         [-1, 1024, 14, 14]               0\n",
      "        Identity-427         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-428         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-429          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-430          [-1, 256, 14, 14]             512\n",
      "            ReLU-431          [-1, 256, 14, 14]               0\n",
      "          Conv2d-432          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-433          [-1, 256, 14, 14]             512\n",
      "            ReLU-434          [-1, 256, 14, 14]               0\n",
      "          Conv2d-435         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-436         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-437         [-1, 1024, 14, 14]               0\n",
      "        Identity-438         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-439         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-440          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-441          [-1, 256, 14, 14]             512\n",
      "            ReLU-442          [-1, 256, 14, 14]               0\n",
      "          Conv2d-443          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-444          [-1, 256, 14, 14]             512\n",
      "            ReLU-445          [-1, 256, 14, 14]               0\n",
      "          Conv2d-446         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-447         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-448         [-1, 1024, 14, 14]               0\n",
      "        Identity-449         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "        Identity-460         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-461         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-462          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-463          [-1, 256, 14, 14]             512\n",
      "            ReLU-464          [-1, 256, 14, 14]               0\n",
      "          Conv2d-465          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-466          [-1, 256, 14, 14]             512\n",
      "            ReLU-467          [-1, 256, 14, 14]               0\n",
      "          Conv2d-468         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-469         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-470         [-1, 1024, 14, 14]               0\n",
      "        Identity-471         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-472         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-473          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-474          [-1, 256, 14, 14]             512\n",
      "            ReLU-475          [-1, 256, 14, 14]               0\n",
      "          Conv2d-476          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-477          [-1, 256, 14, 14]             512\n",
      "            ReLU-478          [-1, 256, 14, 14]               0\n",
      "          Conv2d-479         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-480         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-481         [-1, 1024, 14, 14]               0\n",
      "        Identity-482         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-483         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-484          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-485          [-1, 256, 14, 14]             512\n",
      "            ReLU-486          [-1, 256, 14, 14]               0\n",
      "          Conv2d-487          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-488          [-1, 256, 14, 14]             512\n",
      "            ReLU-489          [-1, 256, 14, 14]               0\n",
      "          Conv2d-490         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-491         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-492         [-1, 1024, 14, 14]               0\n",
      "        Identity-493         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-494         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-495          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-496          [-1, 256, 14, 14]             512\n",
      "            ReLU-497          [-1, 256, 14, 14]               0\n",
      "          Conv2d-498          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-499          [-1, 256, 14, 14]             512\n",
      "            ReLU-500          [-1, 256, 14, 14]               0\n",
      "          Conv2d-501         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-502         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-503         [-1, 1024, 14, 14]               0\n",
      "        Identity-504         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-505         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-506          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-507          [-1, 256, 14, 14]             512\n",
      "            ReLU-508          [-1, 256, 14, 14]               0\n",
      "          Conv2d-509          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-510          [-1, 256, 14, 14]             512\n",
      "            ReLU-511          [-1, 256, 14, 14]               0\n",
      "          Conv2d-512         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-513         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-514         [-1, 1024, 14, 14]               0\n",
      "        Identity-515         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-516         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-517          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-518          [-1, 256, 14, 14]             512\n",
      "            ReLU-519          [-1, 256, 14, 14]               0\n",
      "          Conv2d-520          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-521          [-1, 256, 14, 14]             512\n",
      "            ReLU-522          [-1, 256, 14, 14]               0\n",
      "          Conv2d-523         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-524         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-525         [-1, 1024, 14, 14]               0\n",
      "        Identity-526         [-1, 1024, 14, 14]               0\n",
      "ResBlockBottleneck-527         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-528          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-529          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-530          [-1, 512, 14, 14]               0\n",
      "          Conv2d-531            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-532            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-533            [-1, 512, 7, 7]               0\n",
      "          Conv2d-534           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-535           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-536           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-537           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-538           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-539           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-540           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-541            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-542            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-543            [-1, 512, 7, 7]               0\n",
      "          Conv2d-544            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-545            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-546            [-1, 512, 7, 7]               0\n",
      "          Conv2d-547           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-548           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-549           [-1, 2048, 7, 7]               0\n",
      "        Identity-550           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-551           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-552            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-553            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-554            [-1, 512, 7, 7]               0\n",
      "          Conv2d-555            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-556            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-557            [-1, 512, 7, 7]               0\n",
      "          Conv2d-558           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-559           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-560           [-1, 2048, 7, 7]               0\n",
      "        Identity-561           [-1, 2048, 7, 7]               0\n",
      "ResBlockBottleneck-562           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-563           [-1, 2048, 1, 1]               0\n",
      "          Linear-564                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 58,143,747\n",
      "Trainable params: 58,143,747\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 701.19\n",
      "Params size (MB): 221.80\n",
      "Estimated Total Size (MB): 923.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed152()\n",
    "summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "num_params[3] = 58143747"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([11.1766, 21.2799, 23.5080, 58.1437])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params/(1000000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for step, (data, targets) in enumerate(dl):\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    if step ==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_me is True:\n",
    "    c_start = time.time()\n",
    "\n",
    "num_steps = len(ds.file_names['train'])//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # If we are caching, we now have all data and let the (potentially non-persistent) workers know\n",
    "    if cache_me is True and epoch > 0:\n",
    "        dl.dataset.set_cached(\"train\")\n",
    "        dl.dataset.set_cached(\"val\")\n",
    "\n",
    "    # Time me\n",
    "    if time_me is True:\n",
    "        e_start = time.time()\n",
    "\n",
    "    # Go to train mode\n",
    "    ds.set_mode(\"train\")\n",
    "    model.train()\n",
    "\n",
    "    # Train loop\n",
    "    for step, (data, targets) in enumerate(dl):\n",
    "\n",
    "        # Manually drop last batch (this is for example relevant with BatchNorm)\n",
    "        if step == num_steps - 1 and (epoch > 0 or ds.cache_data is False):\n",
    "            continue\n",
    "\n",
    "        # Train loop: Zero gradients, forward step, evaluate, log, backward step\n",
    "        optimizer.zero_grad()\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        if time_me is True:\n",
    "            c_end = time.time()\n",
    "            if step % mod_step == 0 and wantToPrint:\n",
    "                print(f\"CPU time: {c_end-c_start:.4f}s\")\n",
    "            g_start = time.time()\n",
    "        predictions = model(data)\n",
    "        if time_me is True:\n",
    "            g_end = time.time()\n",
    "            c_start = time.time()\n",
    "        if step % mod_step == 0 and time_me is True and wantToPrint:\n",
    "            print(f\"GPU time: {g_end-g_start:.4f}s\")\n",
    "        loss = criterion(predictions, targets)\n",
    "        if step % mod_step == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}]\\t Step [{step+1}/{num_steps}]\\t Train Loss: {loss.item():.4f}\")\n",
    "        uu.csv_logger(\n",
    "            logfile = f\"../logs/{run_name}_train.csv\",\n",
    "            content = {\"epoch\": epoch, \"step\": step, \"loss\": loss.item()},\n",
    "            first = (epoch == 0 and step == 0),\n",
    "            overwrite = (epoch == 0 and step == 0)\n",
    "                )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Go to eval mode\n",
    "    ds.set_mode(\"val\")\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    val_accuracy, avg_val_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\\t Val Loss: {avg_val_loss:.4f}\\t Val Accuracy: {val_accuracy:.4f}\")\n",
    "    uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_val.csv\",\n",
    "        content = {\"epoch\": epoch, \"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy},\n",
    "        first = (epoch == 0),\n",
    "        overwrite = (epoch == 0)\n",
    "            )\n",
    "\n",
    "    if time_me is True:\n",
    "        cur_time = time.time()-e_start\n",
    "        uu.csv_logger(\n",
    "            logfile = f\"../logs/{run_name}_runtime.csv\",\n",
    "            content = {\"epoch\": epoch, \"time\": cur_time},\n",
    "            first = (epoch == 0),\n",
    "            overwrite = (epoch == 0)\n",
    "                )\n",
    "        print(f\"Epoch nr {epoch+1} time: {time.time()-e_start:.4f}s\")\n",
    "\n",
    "# Finally, test time\n",
    "ds.set_mode(\"test\")\n",
    "model.eval()\n",
    "\n",
    "test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "print(f\"Epoch [{epoch+1}/{epochs}]\\t Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}\")\n",
    "uu.csv_logger(\n",
    "    logfile = f\"../logs/{run_name}_test.csv\",\n",
    "    content = {\"epoch\": epoch, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy},\n",
    "    first = True,\n",
    "    overwrite = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save our model to the disk like so ('../models' means 'go back 1 directory, then into 'models'):\n",
    "def save_model(name, model):\n",
    "    loc = os.path.join(\"../models\", name)\n",
    "    os.makedirs(\"../models\", exist_ok = True)\n",
    "\n",
    "    # To save a DataParallel model generically, save the model.module.state_dict().\n",
    "    # This way, you have the flexibility to load the model any way you want to any device you want.\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), loc)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), loc)\n",
    "#save_model(\"ResNet50_abgabe.tar\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Some useful functions (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sometimes it is conveniently to generalize the training loop.\n",
    "# In my case I often used it to change one parameter and look how the train/validation errors change\n",
    "# I also include this code\n",
    "\n",
    "# training loop function makes the same as training loop upper cell, could be extracted in a separate .py file and imported in the beginning.\n",
    "def training_loop(epochs, optimizer, model, criterion, ds,\n",
    "                  dl, batch_size, run_name, device, cache_me = False, wantToPrint =1,\n",
    "                  mod_step = 500, time_me = True, time = time):\n",
    "    if time_me is True:\n",
    "        c_start = time.time()\n",
    "\n",
    "    num_steps = len(ds.file_names['train'])//batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # If we are caching, we now have all data and let the (potentially non-persistent) workers know\n",
    "        if cache_me is True and epoch > 0:\n",
    "            dl.dataset.set_cached(\"train\")\n",
    "            dl.dataset.set_cached(\"val\")\n",
    "\n",
    "        # Time me\n",
    "        if time_me is True:\n",
    "            e_start = time.time()\n",
    "\n",
    "        # Go to train mode\n",
    "        ds.set_mode(\"train\")\n",
    "        model.train()\n",
    "\n",
    "        # Train loop\n",
    "        for step, (data, targets) in enumerate(dl):\n",
    "\n",
    "            # Manually drop last batch (this is for example relevant with BatchNorm)\n",
    "            if step == num_steps - 1 and (epoch > 0 or ds.cache_data is False):\n",
    "                continue\n",
    "\n",
    "            # Train loop: Zero gradients, forward step, evaluate, log, backward step\n",
    "            optimizer.zero_grad()\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            if time_me is True:\n",
    "                c_end = time.time()\n",
    "                if step % mod_step == 0 and wantToPrint:\n",
    "                    print(f\"CPU time: {c_end-c_start:.4f}s\")\n",
    "                g_start = time.time()\n",
    "            predictions = model(data)\n",
    "            if time_me is True:\n",
    "                g_end = time.time()\n",
    "                c_start = time.time()\n",
    "            if step % mod_step == 0 and time_me is True and wantToPrint:\n",
    "                print(f\"GPU time: {g_end-g_start:.4f}s\")\n",
    "            loss = criterion(predictions, targets)\n",
    "            if step % mod_step == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}]\\t Step [{step+1}/{num_steps}]\\t Train Loss: {loss.item():.4f}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_train.csv\",\n",
    "                content = {\"epoch\": epoch, \"step\": step, \"loss\": loss.item()},\n",
    "                first = (epoch == 0 and step == 0),\n",
    "                overwrite = (epoch == 0 and step == 0)\n",
    "                    )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Go to eval mode\n",
    "        ds.set_mode(\"val\")\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        val_accuracy, avg_val_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\\t Val Loss: {avg_val_loss:.4f}\\t Val Accuracy: {val_accuracy:.4f}\")\n",
    "        uu.csv_logger(\n",
    "            logfile = f\"../logs/{run_name}_val.csv\",\n",
    "            content = {\"epoch\": epoch, \"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy},\n",
    "            first = (epoch == 0),\n",
    "            overwrite = (epoch == 0)\n",
    "                )\n",
    "\n",
    "        if time_me is True:\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_runtime.csv\",\n",
    "                content = {\"epoch\": epoch, \"time\": time.time()-e_start},\n",
    "                first = (epoch == 0 and step == 0),\n",
    "                overwrite = (epoch == 0 and step == 0)\n",
    "                    )\n",
    "            print(f\"Epoch nr {epoch+1} time: {time.time()-e_start:.4f}s\")\n",
    "\n",
    "\n",
    "    # Finally, test time\n",
    "    ds.set_mode(\"test\")\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\\t Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}\")\n",
    "    uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_test.csv\",\n",
    "        content = {\"epoch\": epoch, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy},\n",
    "        first = True,\n",
    "        overwrite = True\n",
    "            )\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    ds = ds, # dataset\n",
    "    dl = dl, # dataloader\n",
    "    batch_size = batch_size,\n",
    "    run_name = run_name,\n",
    "    cache_me = cache_me,\n",
    "    device = device,\n",
    "    wantToPrint = 1, # boolean if want to print GPU and CPU time\n",
    "    mod_step = 500,  # train error will be printed each steps mod this number\n",
    "    time_me = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you want to analyse the logs, it is comfortably to use pandas dataframes for it\n",
    "\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "# creates a pandas dataframe if file exist\n",
    "def create_df_if_exist(path):\n",
    "    if exists(path):\n",
    "        return pd.read_csv(path, sep=',')\n",
    "    else:\n",
    "        print('No file exist', path)\n",
    "        return None\n",
    "\n",
    "# creates 4 dataframes, with validate, train, test and runtime logs.\n",
    "def create_dfs_filename(path):\n",
    "    path_val = path + '_val.csv'\n",
    "    path_train =  path + '_train.csv'\n",
    "    path_test = path + '_test.csv'\n",
    "    path_runtime = path + '_runtime.csv'\n",
    "\n",
    "    return create_df_if_exist(path_val), create_df_if_exist(path_train), create_df_if_exist(path_test), create_df_if_exist(path_runtime)\n",
    "\n",
    "\n",
    "logs_folder = '/home/coder/Course_Materials/logs/'\n",
    "filename = 'AlexNet'\n",
    "df_AlexNet_val, df_AlexNet_train, df_AlexNet_test, df_AlexNet_runtime = create_dfs_filename(logs_folder+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a simple function to plot an image from torch.tensor\n",
    "# we need a utility function to switch dimensions from [channel*Height*Width] to [Height*Width*Channel] and convert tensor to numpy array\n",
    "def plotImg(tensor_image_in, cmap = 'bone'):\n",
    "    tensor_image = tensor_image_in.to('cpu')\n",
    "    array_image = uu.convert_tensor_to_opencv_array(tensor_image)\n",
    "    plt.figure()\n",
    "    plt.imshow(array_image, cmap=cmap)\n",
    "    plt.xlim((0, 256))\n",
    "    plt.ylim((0, 256))\n",
    "    plt.title(\"Image\")\n",
    "    plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5555b6f2b0077a97828fbbfe12cb97727895c9c472121c1b71224aa97370345d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
