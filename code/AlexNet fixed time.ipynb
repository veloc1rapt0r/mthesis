{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet\n",
    "This notebook was motivated by\n",
    "[1] Alex Krizhevsky, Ilya Sutskever and Geoffrey E Hinton. ‘ImageNet Classification with Deep Convolutional Neural Networks’. In: (2012). url: https://proceedings.neurips.cc/paper/2012/file/c 399862d3b9d6b76c8436e924a68c45b-Paper.pdf.\n",
    "\n",
    "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n",
    "\n",
    "Implementation: Oleh Bakumenko, Univerity of Duisburg-Essen\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # Otherwise, import from the local folder's parent folder, where your stuff lives.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "import torchvision, torchvision.transforms as tt\n",
    "from torch.multiprocessing import Manager\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "from pathlib import Path\n",
    "\n",
    "from utility import utils as uu\n",
    "from utility.eval import evaluate_classifier_model\n",
    "from utility.confusion_matrix import calculate_confusion_matrix\n",
    "\n",
    "from utility.trainLoopClassifier import *\n",
    "from utility.plotImageModel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augments = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.RandomHorizontalFlip(p = .5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p = .5),\n",
    "    torchvision.transforms.ColorJitter(brightness=(0.5,1.5), contrast=(1), hue=(-0.1,0.1)),\n",
    "    torchvision.transforms.RandomCrop((224, 224)), \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the dataset from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = Path(\"plots_and_graphs.ipynb\")\n",
    "parent_dir = cur_path.parent.absolute()\n",
    "masterThesis_folder = str(parent_dir.parent.absolute())+'/'\n",
    "data_dir = masterThesis_folder+\"data/Clean_LiTS/\"\n",
    "\n",
    "cache_me = False\n",
    "if cache_me is True:\n",
    "    cache_mgr = Manager()\n",
    "    cache_mgr.data = cache_mgr.dict()\n",
    "    cache_mgr.cached = cache_mgr.dict()\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        cache_mgr.data[k] = cache_mgr.dict()\n",
    "        cache_mgr.cached[k] = False\n",
    "# function from utils, credit: Institute for Artificial Intelligence in Medicine. url: https://mml.ikim.nrw/\n",
    "# dataset outputs a tensor image (dimensions [1,256,256]) and a tensor target (0, 1 or 2)\n",
    "\n",
    "ds = uu.LiTS_Classification_Dataset(\n",
    "    data_dir=data_dir,\n",
    "    transforms=data_augments,\n",
    "    verbose=True,\n",
    "    cache_data=cache_me,\n",
    "    cache_mgr=(cache_mgr if cache_me is True else None),\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "time_me  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `torch.utils.data.DataLoader` is a utility class in PyTorch that makes the loading and batching of data for training purposes faster. It simplifies the process by allowing us to specify the dataset, batch size (often 32), and whether the data should be shuffled before each epoch. Additionally, there are other parameters available to further customize the data loading process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset = ds, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = 4, \n",
    "    shuffle = True, \n",
    "    drop_last = False, \n",
    "    pin_memory = True,\n",
    "    persistent_workers = (not cache_me),\n",
    "    prefetch_factor = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet\n",
    "\n",
    "AlexNet is a deep convolutional neural network architecture that was introduced in 2012 by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It was one of the first successful models to use deep convolutional neural networks for image classification and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. AlexNet consists of eight layers, including five convolutional layers and three fully connected layers, and uses ReLU activation functions and pooling layers to reduce the dimensionality of the input data.\n",
    "\n",
    "Some bullet points:\n",
    "1. ReLU activation function instead of tanh.\n",
    "2. Using dropout to reduce overfitting.\n",
    "3. Main idea: convolution followed by max pooling, and stacking of these layers; using dropout for fully connected layers.\n",
    "4. Using parallel computations on multiple GPUs (not included here).\n",
    "5. Local Response Normalization - not used in future networks; see torch.nn.LocalResponseNorm.\n",
    "\n",
    "Overall architecture and channel sizes can be found in [1]."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet Class\n",
    "#       - constructs a convolutional neuronal network as described in [1]\n",
    "# Input:    Tensor: [Batch,1,Height,Width]\n",
    "# Output:   Tensor: [Batch,3]\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlexNetMLMed(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetMLMed, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 96, kernel_size = (11,11), stride = (4,4), padding=1)        \n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        self.responseNorm = torch.nn.LocalResponseNorm(5)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = (5, 5), stride = (1,1),padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = (3, 3), stride = (1,1),padding=1)\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = (3, 3), stride = (1,1),padding=1)\n",
    "\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = (3, 3), stride = (1,1),padding=1)\n",
    "\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.5) \n",
    "\n",
    "        self.fc1 = nn.Linear(9216,4096)\n",
    "        self.fc1_1 = nn.Linear(6400,4096)\n",
    "\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,3)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.pool1(out)\n",
    "        out = self.responseNorm(out)\n",
    "\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.pool2(out)\n",
    "        out = self.responseNorm(out)\n",
    "\n",
    "\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.relu(self.conv5(out))\n",
    "        out = self.pool4(out)\n",
    "\n",
    "\n",
    "        out = out.flatten(start_dim=1)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc1_1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = AlexNetMLMed()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (data, targets) in enumerate(dl):\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    if step ==1:\n",
    "        break\n",
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "run_name = \"AlexNet_fixed_time_lre5\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_hyperparams.csv\",\n",
    "        content = {\"learning_rate\": learning_rate, \"batch_size\": batch_size, \"epochs\": epochs},\n",
    "        first= True,\n",
    "        overwrite= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_step = 5000\n",
    "wantToPrint = False\n",
    "stop_bool = False\n",
    "eval_test_10_min = False\n",
    "eval_test_15_min = False\n",
    "eval_test_20_min = False\n",
    "skip_test_10_min = False\n",
    "skip_test_15_min = False\n",
    "skip_test_20_min = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modified training loop. The starting time is saved. Time elapsed is calcualated at the beginning of the epoch and if it is > 10, 15 or 20 minutes the boolean flag for the test evaluation is set to True; Howewer it is important that the test evaluation only one time happens, therefore after the calculation the boolen flag for skip is set to true. This ensure that the test evaluation happens only one time.\n",
    "\n",
    "During the test evaluation the dataset mode is switched to \"test\", model is turned to the evaluation mode and the test accuracy, loss, confusion matrix and per class accuracy is calculated and saved.\n",
    "The same procedure repeted 3 times for each time step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "num_steps = len(ds.file_names['train'])//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    time_elapsed = time.time() - train_start\n",
    "    print(f\"Time_elapsed: {time_elapsed/60 :.2f} min\")\n",
    "    if time_elapsed > 10*60:\n",
    "        eval_test_10_min = True\n",
    "    if time_elapsed > 15*60:\n",
    "        eval_test_15_min = True\n",
    "    if time_elapsed > 20*60:\n",
    "        eval_test_20_min = True\n",
    "\n",
    "    if eval_test_10_min and not skip_test_10_min:\n",
    "        print('Evaluate after first 10 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_10min' + '.pt')\n",
    "            print(f\"Evaluate after first 10 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 1, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_10_min = True\n",
    "\n",
    "    if eval_test_15_min and not skip_test_15_min:\n",
    "        print('Evaluate after first 15 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_15min' + '.pt')\n",
    "            print(f\"Evaluate after first 15 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 2, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_15_min = True\n",
    "\n",
    "    if eval_test_20_min and not skip_test_20_min:\n",
    "        print('Evaluate after first 20 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_20min' + '.pt')\n",
    "            print(f\"Evaluate after first 20 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 3, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_20_min = True\n",
    "\n",
    "        break\n",
    "\n",
    "    # Go to train mode\n",
    "    ds.set_mode(\"train\")\n",
    "    model.train()\n",
    "\n",
    "    # Train loop\n",
    "    for step, (data, targets) in enumerate(dl):\n",
    "\n",
    "        # Manually drop last batch (this is for example relevant with BatchNorm)\n",
    "        if step == num_steps - 1 and (epoch > 0 or ds.cache_data is False):\n",
    "            continue\n",
    "\n",
    "        # Train loop: Zero gradients, forward step, evaluate, log, backward step\n",
    "        optimizer.zero_grad()\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Go to eval mode\n",
    "    ds.set_mode(\"val\")\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    val_accuracy, avg_val_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\\t Val Loss: {avg_val_loss:.4f}\\t Val Accuracy: {val_accuracy:.4f}\")\n",
    "    uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_val.csv\",\n",
    "        content = {\"epoch\": epoch, \"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy},\n",
    "        first = (epoch == 0),\n",
    "        overwrite = (epoch == 0)\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"AlexNet_fixed_time_lre4\"\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNetMLMed()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_bool = False\n",
    "eval_test_10_min = False\n",
    "eval_test_15_min = False\n",
    "eval_test_20_min = False\n",
    "skip_test_10_min = False\n",
    "skip_test_15_min = False\n",
    "skip_test_20_min = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "num_steps = len(ds.file_names['train'])//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    time_elapsed = time.time() - train_start\n",
    "    print(f\"Time_elapsed: {time_elapsed/60 :.2f} min\")\n",
    "    if time_elapsed > 10*60:\n",
    "        eval_test_10_min = True\n",
    "    if time_elapsed > 15*60:\n",
    "        eval_test_15_min = True\n",
    "    if time_elapsed > 20*60:\n",
    "        eval_test_20_min = True\n",
    "\n",
    "    if eval_test_10_min and not skip_test_10_min:\n",
    "        print('Evaluate after first 10 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_10min' + '.pt')\n",
    "            print(f\"Evaluate after first 10 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 1, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_10_min = True\n",
    "\n",
    "    if eval_test_15_min and not skip_test_15_min:\n",
    "        print('Evaluate after first 15 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_15min' + '.pt')\n",
    "            print(f\"Evaluate after first 15 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 2, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_15_min = True\n",
    "\n",
    "    if eval_test_20_min and not skip_test_20_min:\n",
    "        print('Evaluate after first 20 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_20min' + '.pt')\n",
    "            print(f\"Evaluate after first 20 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 3, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        break\n",
    "\n",
    "    # Go to train mode\n",
    "    ds.set_mode(\"train\")\n",
    "    model.train()\n",
    "\n",
    "    # Train loop\n",
    "    for step, (data, targets) in enumerate(dl):\n",
    "\n",
    "        # Manually drop last batch (this is for example relevant with BatchNorm)\n",
    "        if step == num_steps - 1 and (epoch > 0 or ds.cache_data is False):\n",
    "            continue\n",
    "\n",
    "        # Train loop: Zero gradients, forward step, evaluate, log, backward step\n",
    "        optimizer.zero_grad()\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Go to eval mode\n",
    "    ds.set_mode(\"val\")\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    val_accuracy, avg_val_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\\t Val Loss: {avg_val_loss:.4f}\\t Val Accuracy: {val_accuracy:.4f}\")\n",
    "    uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_val.csv\",\n",
    "        content = {\"epoch\": epoch, \"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy},\n",
    "        first = (epoch == 0),\n",
    "        overwrite = (epoch == 0)\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"AlexNet_fixed_time_lre3\"\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNetMLMed()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_bool = False\n",
    "eval_test_10_min = False\n",
    "eval_test_15_min = False\n",
    "eval_test_20_min = False\n",
    "skip_test_10_min = False\n",
    "skip_test_15_min = False\n",
    "skip_test_20_min = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "num_steps = len(ds.file_names['train'])//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    time_elapsed = time.time() - train_start\n",
    "    print(f\"Time_elapsed: {time_elapsed/60 :.2f} min\")\n",
    "    if time_elapsed > 10*60:\n",
    "        eval_test_10_min = True\n",
    "    if time_elapsed > 15*60:\n",
    "        eval_test_15_min = True\n",
    "    if time_elapsed > 20*60:\n",
    "        eval_test_20_min = True\n",
    "\n",
    "    if eval_test_10_min and not skip_test_10_min:\n",
    "        print('Evaluate after first 10 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_10min' + '.pt')\n",
    "            print(f\"Evaluate after first 10 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 1, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_10_min = True\n",
    "\n",
    "    if eval_test_15_min and not skip_test_15_min:\n",
    "        print('Evaluate after first 15 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_15min' + '.pt')\n",
    "            print(f\"Evaluate after first 15 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 2, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        skip_test_15_min = True\n",
    "\n",
    "    if eval_test_20_min and not skip_test_20_min:\n",
    "        print('Evaluate after first 20 min')\n",
    "        with torch.no_grad():\n",
    "            ds.set_mode(\"test\")\n",
    "            model.eval()\n",
    "            test_accuracy, avg_test_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "            confusion_matrix, acc = calculate_confusion_matrix(model=model, dataloader=dl, device=device)\n",
    "            torch.save(confusion_matrix, f = 'confusion_matr_' + run_name+ '_20min' + '.pt')\n",
    "            print(f\"Evaluate after first 20 min: Test Loss: {avg_test_loss:.4f}\\t Test Accuracy: {test_accuracy:.4f}, Confusion Matrix: \\n{confusion_matrix}, Per-class Accuracy: {acc}\")\n",
    "            uu.csv_logger(\n",
    "                logfile = f\"../logs/{run_name}_test.csv\",\n",
    "                content = {\"epoch\": epoch,\"test_phase\": 3, \"test_loss\": avg_test_loss, \"test_accuracy\": test_accuracy, \"time_elapsed\": time_elapsed})\n",
    "        break\n",
    "\n",
    "    # Go to train mode\n",
    "    ds.set_mode(\"train\")\n",
    "    model.train()\n",
    "\n",
    "    # Train loop\n",
    "    for step, (data, targets) in enumerate(dl):\n",
    "\n",
    "        # Manually drop last batch (this is for example relevant with BatchNorm)\n",
    "        if step == num_steps - 1 and (epoch > 0 or ds.cache_data is False):\n",
    "            continue\n",
    "\n",
    "        # Train loop: Zero gradients, forward step, evaluate, log, backward step\n",
    "        optimizer.zero_grad()\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Go to eval mode\n",
    "    ds.set_mode(\"val\")\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    val_accuracy, avg_val_loss = evaluate_classifier_model(model = model, dataloader = dl, device = device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\\t Val Loss: {avg_val_loss:.4f}\\t Val Accuracy: {val_accuracy:.4f}\")\n",
    "    uu.csv_logger(\n",
    "        logfile = f\"../logs/{run_name}_val.csv\",\n",
    "        content = {\"epoch\": epoch, \"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy},\n",
    "        first = (epoch == 0),\n",
    "        overwrite = (epoch == 0)\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5555b6f2b0077a97828fbbfe12cb97727895c9c472121c1b71224aa97370345d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
