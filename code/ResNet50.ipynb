{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook was motivated by\n",
    "\n",
    "[2] Kaiming He et al. ‘Deep Residual Learning for Image Recognition’. In: CoRR abs/1512.03385 (2015). arXiv: 1512.03385.\n",
    "url: http: //arxiv.org/abs/1512.03385.\n",
    "\n",
    "Implementation: Oleh Bakumenko, University of Duisburg-Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "import torchvision, torchvision.transforms as tt\n",
    "from torchsummary import summary\n",
    "from torch.multiprocessing import Manager\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "from pathlib import Path\n",
    "\n",
    "from utility import utils as uu\n",
    "from utility.eval import evaluate_classifier_model\n",
    "from utility.confusion_matrix import calculate_confusion_matrix\n",
    "from utility.trainLoopClassifier import *\n",
    "from utility.plotImageModel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data augmentation is a technique used to artificially increase the size of a dataset by transforming existing data points to create new, similar instances. This can help prevent overfitting in machine learning models, as well as improve their ability to generalize to unseen data. Common types of data augmentation include flipping, rotation, scaling, and adding noise to images.\n",
    "We can generate the augmentation list with torchvision.transforms module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augments = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.RandomHorizontalFlip(p = .5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p = .5),\n",
    "    torchvision.transforms.ColorJitter(brightness=(0.5,1.5), contrast=(1), hue=(-0.1,0.1)),\n",
    "    #torchvision.transforms.RandomCrop((224, 224)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the dataset from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = Path(\"plots_and_graphs.ipynb\")\n",
    "parent_dir = cur_path.parent.absolute()\n",
    "masterThesis_folder = str(parent_dir.parent.absolute())+'/'\n",
    "data_dir = masterThesis_folder+\"data/Clean_LiTS/\"\n",
    "\n",
    "cache_me = False\n",
    "if cache_me is True:\n",
    "    cache_mgr = Manager()\n",
    "    cache_mgr.data = cache_mgr.dict()\n",
    "    cache_mgr.cached = cache_mgr.dict()\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        cache_mgr.data[k] = cache_mgr.dict()\n",
    "        cache_mgr.cached[k] = False\n",
    "# function from utils, credit: Institute for Artificial Intelligence in Medicine. url: https://mml.ikim.nrw/\n",
    "# dataset outputs a tensor image (dimensions [1,256,256]) and a tensor target (0, 1 or 2)\n",
    "\n",
    "ds = uu.LiTS_Classification_Dataset(\n",
    "    data_dir=data_dir,\n",
    "    transforms=data_augments,\n",
    "    verbose=True,\n",
    "    cache_data=cache_me,\n",
    "    cache_mgr=(cache_mgr if cache_me is True else None),\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "epochs = 15\n",
    "run_name = \"ResNet50\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "time_me  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `torch.utils.data.DataLoader` is a utility class in PyTorch that makes the loading and batching of data for training purposes faster. It simplifies the process by allowing us to specify the dataset, batch size (often 32), and whether the data should be shuffled before each epoch. Additionally, there are other parameters available to further customize the data loading process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset = ds, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = 4, \n",
    "    shuffle = True, \n",
    "    drop_last = False, \n",
    "    pin_memory = True,\n",
    "    persistent_workers = (not cache_me),\n",
    "    prefetch_factor = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet (Residual Network) is a deep neural network architecture introduced in 2015 in [2]. It was designed to address the issue of vanishing gradients in very deep networks. ResNet is named as such because it utilizes residual connections (skip connections), which enable the flow of gradients from earlier layers to later layers, even in very deep networks.\n",
    "\n",
    "The residual connections in ResNet involve adding the input of a layer to the output of a layer that is several layers deeper. This allows the network to more easily learn identity functions. This design helps prevent the issue of vanishing gradients and enables ResNet to train much deeper networks than was previously possible. This architecture has shown significant improvements in benchmarks compared to the earlier AlexNet model.\n",
    "\n",
    "The original ResNet was used in the ImageNet Challenge to classify 1000 classes. However, in our exercise, we only use 3 classes:\n",
    "0: Image does not include the liver.\n",
    "1: Liver is visible.\n",
    "2: Liver is visible and a lesion is visible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ResNet50 introduced a new structure called the bottleneck block, which consists of a sequence of [convolution -> batch normalization -> activation] repeated three times. In addition to the 3x3 convolution, the number of channels is also modified within each block using a 1x1 convolution.\n",
    "\n",
    "To provide more flexibility for customization, the variables \"number of channels in,\" \"between,\" and \"out\" are specified for the block. In most cases, the number of input channels will be the same as the number of output channels.\n",
    "\n",
    "A generalized solution is used to address the downsampling issue. Instead of using two different blocks as in ResNet34, a boolean variable and a stride are defined for this purpose. If downsampling is required at the beginning of resblocks3-5, we set \"downsample\" to True and \"stride\" to 2. It's important to note that there is no need to change the stride in the second part of resblocks2.\n",
    "If downsampling is not needed, the operation will be set to nn.Identity()."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A few words about the torch.nn.init part:\n",
    "PyTorch initializes the parameters for Conv and batch norm randomly from uniform distribution. Initialization of the weights and biases with a normal distribution helps the model backpropagate gradients in early epochs.\n",
    "\n",
    "Tests were conducted on smaller models with 18, 34, and 50 layers, indicating that for adaptive optimizers, weight and bias initialization has minimal effect on model performance or convergence.\n",
    "\n",
    "In contrast, the uniform initialized ResNet 152 model exhibited poor convergence after 15 epochs, with very high error and low accuracy rates. Although initialization improved the performance, it still required tuning of hyperparameters and a better optimizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResBlockBottleneck Class\n",
    "#       - constructs a block [conv -> batch_norm -> activation]*3, which we will stack in the network\n",
    "# Input:    int: num_chans_in, int:num_chans_between, int:num_chans_out\n",
    "#           boolean: downsample = False, set True if first block\n",
    "#           int: stride = 1, set 2 if want to downsample\n",
    "# Output:   nn.Sequential() block\n",
    "class ResBlockBottleneck(nn.Module):\n",
    "    def __init__(self, num_chans_in,n_chans_between,num_chans_out, downsample = False, stride = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_chans_in, n_chans_between, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans_between, n_chans_between, kernel_size=3, stride= stride, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(n_chans_between, num_chans_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(num_features=num_chans_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv3.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm3.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm3.bias)\n",
    "\n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(num_chans_in, num_chans_out, kernel_size=1,padding=0,stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=num_chans_out),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.relu(out)\n",
    "        return out + self.downsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ResNetMLMed50 Class\n",
    "#       - constructs a ResNet50 as described in [2, Table 1].\n",
    "# Input:    Tensor: [Batch,1,Height,Width]\n",
    "# Output:   Tensor: [Batch,3]\n",
    "class ResNetMLMed50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2,padding=1)\n",
    "        self.resblocks2 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 64,n_chans_between =64 ,num_chans_out=256,downsample= True),\n",
    "            *(2 * [ResBlockBottleneck(num_chans_in = 256,n_chans_between=64,num_chans_out= 256)]))\n",
    "        self.resblocks3 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 256, n_chans_between=128, num_chans_out= 512, downsample=True, stride=2),\n",
    "            *(3 * [ResBlockBottleneck(num_chans_in = 512,n_chans_between=128,num_chans_out= 512)]))\n",
    "        self.resblocks4 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 512, n_chans_between=256, num_chans_out= 1024,downsample=True, stride=2),\n",
    "            *(5 * [ResBlockBottleneck(num_chans_in = 1024,n_chans_between=256,num_chans_out= 1024)]))\n",
    "        self.resblocks5 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 1024, n_chans_between=512, num_chans_out= 2048,downsample=True, stride=2),\n",
    "            *(2 * [ResBlockBottleneck(num_chans_in = 2048,n_chans_between=512,num_chans_out= 2048)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=2048, out_features=3, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4= self.resblocks4(out_3)\n",
    "\n",
    "        out_5= self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "        return out_6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 126, 126]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 126, 126]             128\n",
      "              ReLU-3         [-1, 64, 126, 126]               0\n",
      "         MaxPool2d-4           [-1, 64, 63, 63]               0\n",
      "            Conv2d-5           [-1, 64, 63, 63]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 63, 63]             128\n",
      "              ReLU-7           [-1, 64, 63, 63]               0\n",
      "            Conv2d-8           [-1, 64, 63, 63]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 63, 63]             128\n",
      "             ReLU-10           [-1, 64, 63, 63]               0\n",
      "           Conv2d-11          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 63, 63]             512\n",
      "             ReLU-13          [-1, 256, 63, 63]               0\n",
      "           Conv2d-14          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 63, 63]             512\n",
      "             ReLU-16          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-17          [-1, 256, 63, 63]               0\n",
      "           Conv2d-18           [-1, 64, 63, 63]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 63, 63]             128\n",
      "             ReLU-20           [-1, 64, 63, 63]               0\n",
      "           Conv2d-21           [-1, 64, 63, 63]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 63, 63]             128\n",
      "             ReLU-23           [-1, 64, 63, 63]               0\n",
      "           Conv2d-24          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 63, 63]             512\n",
      "             ReLU-26          [-1, 256, 63, 63]               0\n",
      "         Identity-27          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-28          [-1, 256, 63, 63]               0\n",
      "           Conv2d-29           [-1, 64, 63, 63]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 63, 63]             128\n",
      "             ReLU-31           [-1, 64, 63, 63]               0\n",
      "           Conv2d-32           [-1, 64, 63, 63]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 63, 63]             128\n",
      "             ReLU-34           [-1, 64, 63, 63]               0\n",
      "           Conv2d-35          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 63, 63]             512\n",
      "             ReLU-37          [-1, 256, 63, 63]               0\n",
      "         Identity-38          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-39          [-1, 256, 63, 63]               0\n",
      "           Conv2d-40          [-1, 128, 63, 63]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 63, 63]             256\n",
      "             ReLU-42          [-1, 128, 63, 63]               0\n",
      "           Conv2d-43          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 32, 32]             256\n",
      "             ReLU-45          [-1, 128, 32, 32]               0\n",
      "           Conv2d-46          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-52          [-1, 512, 32, 32]               0\n",
      "           Conv2d-53          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 32, 32]             256\n",
      "             ReLU-55          [-1, 128, 32, 32]               0\n",
      "           Conv2d-56          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 32, 32]             256\n",
      "             ReLU-58          [-1, 128, 32, 32]               0\n",
      "           Conv2d-59          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-61          [-1, 512, 32, 32]               0\n",
      "         Identity-62          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-63          [-1, 512, 32, 32]               0\n",
      "           Conv2d-64          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 32, 32]             256\n",
      "             ReLU-66          [-1, 128, 32, 32]               0\n",
      "           Conv2d-67          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 32, 32]             256\n",
      "             ReLU-69          [-1, 128, 32, 32]               0\n",
      "           Conv2d-70          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-72          [-1, 512, 32, 32]               0\n",
      "         Identity-73          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-74          [-1, 512, 32, 32]               0\n",
      "           Conv2d-75          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 32, 32]             256\n",
      "             ReLU-77          [-1, 128, 32, 32]               0\n",
      "           Conv2d-78          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 32, 32]             256\n",
      "             ReLU-80          [-1, 128, 32, 32]               0\n",
      "           Conv2d-81          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-83          [-1, 512, 32, 32]               0\n",
      "         Identity-84          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-85          [-1, 512, 32, 32]               0\n",
      "           Conv2d-86          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 32, 32]             512\n",
      "             ReLU-88          [-1, 256, 32, 32]               0\n",
      "           Conv2d-89          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 16, 16]             512\n",
      "             ReLU-91          [-1, 256, 16, 16]               0\n",
      "           Conv2d-92         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-93         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-94         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-95         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-96         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-97         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-98         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-99          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-100          [-1, 256, 16, 16]             512\n",
      "            ReLU-101          [-1, 256, 16, 16]               0\n",
      "          Conv2d-102          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-103          [-1, 256, 16, 16]             512\n",
      "            ReLU-104          [-1, 256, 16, 16]               0\n",
      "          Conv2d-105         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-106         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-107         [-1, 1024, 16, 16]               0\n",
      "        Identity-108         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-109         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-110          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 16, 16]             512\n",
      "            ReLU-112          [-1, 256, 16, 16]               0\n",
      "          Conv2d-113          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 16, 16]             512\n",
      "            ReLU-115          [-1, 256, 16, 16]               0\n",
      "          Conv2d-116         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-117         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-118         [-1, 1024, 16, 16]               0\n",
      "        Identity-119         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "        Identity-130         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-131         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-132          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-133          [-1, 256, 16, 16]             512\n",
      "            ReLU-134          [-1, 256, 16, 16]               0\n",
      "          Conv2d-135          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-136          [-1, 256, 16, 16]             512\n",
      "            ReLU-137          [-1, 256, 16, 16]               0\n",
      "          Conv2d-138         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-139         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-140         [-1, 1024, 16, 16]               0\n",
      "        Identity-141         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-142         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-143          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 16, 16]             512\n",
      "            ReLU-145          [-1, 256, 16, 16]               0\n",
      "          Conv2d-146          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 16, 16]             512\n",
      "            ReLU-148          [-1, 256, 16, 16]               0\n",
      "          Conv2d-149         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-151         [-1, 1024, 16, 16]               0\n",
      "        Identity-152         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-153         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-154          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-155          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-156          [-1, 512, 16, 16]               0\n",
      "          Conv2d-157            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-158            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-159            [-1, 512, 8, 8]               0\n",
      "          Conv2d-160           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-161           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-162           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-163           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-165           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-166           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-167            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-168            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-169            [-1, 512, 8, 8]               0\n",
      "          Conv2d-170            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-171            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-172            [-1, 512, 8, 8]               0\n",
      "          Conv2d-173           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-174           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-175           [-1, 2048, 8, 8]               0\n",
      "        Identity-176           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-177           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-178            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-179            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-180            [-1, 512, 8, 8]               0\n",
      "          Conv2d-181            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-182            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-183            [-1, 512, 8, 8]               0\n",
      "          Conv2d-184           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-185           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-186           [-1, 2048, 8, 8]               0\n",
      "        Identity-187           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-188           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-189           [-1, 2048, 1, 1]               0\n",
      "          Linear-190                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 23,507,971\n",
      "Trainable params: 23,507,971\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 422.75\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 512.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed50()\n",
    "summary(model, (1, 256, 256))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (data, targets) in enumerate(dl):\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    if step ==1:\n",
    "        break\n",
    "model = model.to(device)\n",
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop_conf_matr(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    ds = ds,\n",
    "    dl = dl,\n",
    "    batch_size = batch_size,\n",
    "    run_name = run_name,\n",
    "    device = device,\n",
    "    time_me=True,\n",
    "    time=time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5555b6f2b0077a97828fbbfe12cb97727895c9c472121c1b71224aa97370345d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
