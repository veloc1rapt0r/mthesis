{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This notebook was motivated by\n",
    "\n",
    "[2] Kaiming He et al. ‘Deep Residual Learning for Image Recognition’. In: CoRR abs/1512.03385 (2015). arXiv: 1512.03385.\n",
    "url: http: //arxiv.org/abs/1512.03385.\n",
    "\n",
    "Implementation: Oleh Bakumenko, University of Duisburg-Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "import torchvision, torchvision.transforms as tt\n",
    "from torch.multiprocessing import Manager\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "\n",
    "from utility import utils as uu\n",
    "from utility.eval import evaluate_classifier_model\n",
    "\n",
    "from utility.trainLoopClassifier import *\n",
    "from utility.plotImageModel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data augmentation is a technique used to artificially increase the size of a dataset by transforming existing data points to create new, similar instances. This can help prevent overfitting in machine learning models, as well as improve their ability to generalize to unseen data. Common types of data augmentation include flipping, rotation, scaling, and adding noise to images.\n",
    "We can generate the augmentation list with torchvision.transforms module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augments = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.RandomHorizontalFlip(p = .5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p = .5),\n",
    "    torchvision.transforms.ColorJitter(brightness=(0.5,1.5), contrast=(1), hue=(-0.1,0.1)),\n",
    "    #torchvision.transforms.RandomCrop((224, 224)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the dataset from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66b751ddd4764a22befd7960a7cb5523"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3039 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b7c68732912473d826129d88024d079"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3038 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86e010fc366c4ac69d784ab55e4f80ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccc03ef67a6c4da9853f5eba6661fa37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3039 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e48ee6f45e3a4becb66a69552ecf3673"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3038 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83d5ea6e0ae141b4a864cf99afd21b58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialization complete.\n"
     ]
    }
   ],
   "source": [
    "cur_path = Path(\"plots_and_graphs.ipynb\")\n",
    "parent_dir = cur_path.parent.absolute()\n",
    "masterThesis_folder = str(parent_dir.parent.absolute())+'/'\n",
    "data_dir = masterThesis_folder+\"data/Clean_LiTS/\"\n",
    "\n",
    "cache_me = False\n",
    "if cache_me is True:\n",
    "    cache_mgr = Manager()\n",
    "    cache_mgr.data = cache_mgr.dict()\n",
    "    cache_mgr.cached = cache_mgr.dict()\n",
    "    for k in [\"train\", \"val\", \"test\"]:\n",
    "        cache_mgr.data[k] = cache_mgr.dict()\n",
    "        cache_mgr.cached[k] = False\n",
    "# function from utils, credit: Institute for Artificial Intelligence in Medicine. url: https://mml.ikim.nrw/\n",
    "# dataset outputs a tensor image (dimensions [1,256,256]) and a tensor target (0, 1 or 2)\n",
    "\n",
    "ds = uu.LiTS_Classification_Dataset(\n",
    "    data_dir=data_dir,\n",
    "    transforms=data_augments,\n",
    "    verbose=True,\n",
    "    cache_data=cache_me,\n",
    "    cache_mgr=(cache_mgr if cache_me is True else None),\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "epochs = 15\n",
    "run_name = \"ResNet152\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "time_me  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `torch.utils.data.DataLoader` is a utility class in PyTorch that makes the loading and batching of data for training purposes faster. It simplifies the process by allowing us to specify the dataset, batch size (often 32), and whether the data should be shuffled before each epoch. Additionally, there are other parameters available to further customize the data loading process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset = ds, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = 4, \n",
    "    shuffle = True, \n",
    "    drop_last = False, \n",
    "    pin_memory = True,\n",
    "    persistent_workers = (not cache_me),\n",
    "    prefetch_factor = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet (Residual Network) is a deep neural network architecture introduced in 2015 in [2]. It was designed to address the issue of vanishing gradients in very deep networks. ResNet is named as such because it utilizes residual connections (skip connections), which enable the flow of gradients from earlier layers to later layers, even in very deep networks.\n",
    "\n",
    "The residual connections in ResNet involve adding the input of a layer to the output of a layer that is several layers deeper. This allows the network to more easily learn identity functions. This design helps prevent the issue of vanishing gradients and enables ResNet to train much deeper networks than was previously possible. This architecture has shown significant improvements in benchmarks compared to the earlier AlexNet model.\n",
    "\n",
    "The original ResNet was used in the ImageNet Challenge to classify 1000 classes. However, in our exercise, we only use 3 classes:\n",
    "0: Image does not include the liver.\n",
    "1: Liver is visible.\n",
    "2: Liver is visible and a lesion is visible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet50 introduced a new structure called the bottleneck block, which consists of a sequence of [convolution -> batch normalization -> activation] repeated three times. In addition to the 3x3 convolution, the number of channels is also modified within each block using a 1x1 convolution.\n",
    "\n",
    "To provide more flexibility for customization, the variables \"number of channels in,\" \"between,\" and \"out\" are specified for the block. In most cases, the number of input channels will be the same as the number of output channels.\n",
    "\n",
    "A generalized solution is used to address the downsampling issue. Instead of using two different blocks as in ResNet34, a boolean variable and a stride are defined for this purpose. If downsampling is required at the beginning of resblocks3-5, we set \"downsample\" to True and \"stride\" to 2. It's important to note that there is no need to change the stride in the second part of resblocks2.\n",
    "If downsampling is not needed, the operation will be set to nn.Identity()."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A few words about the torch.nn.init part:\n",
    "PyTorch initializes the parameters for Conv and batch norm randomly from uniform distribution. Initialization of the weights and biases with a normal distribution helps the model backpropagate gradients in early epochs.\n",
    "\n",
    "Tests were conducted on smaller models with 18, 34, and 50 layers, indicating that for adaptive optimizers, weight and bias initialization has minimal effect on model performance or convergence.\n",
    "\n",
    "In contrast, the uniform initialized ResNet 152 model exhibited poor convergence after 15 epochs, with very high error and low accuracy rates. Although initialization improved the performance, it still required tuning of hyperparameters and a better optimizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResBlockBottleneck Class\n",
    "#       - constructs a block [conv -> batch_norm -> activation]*3, which we will stack in the network\n",
    "# Input:    int: num_chans_in, int:num_chans_between, int:num_chans_out\n",
    "#           boolean: downsample = False, set True if first block\n",
    "#           int: stride = 1, set 2 if want to downsample\n",
    "# Output:   nn.Sequential() block\n",
    "class ResBlockBottleneck(nn.Module):\n",
    "    def __init__(self, num_chans_in,n_chans_between,num_chans_out, downsample = False, stride = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_chans_in, n_chans_between, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(n_chans_between, n_chans_between, kernel_size=3, stride= stride, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans_between)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(n_chans_between, num_chans_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(num_features=num_chans_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
    "                                      nonlinearity='relu')\n",
    "        torch.nn.init.kaiming_normal_(self.conv3.weight,\n",
    "                                      nonlinearity='relu')\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm3.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm3.bias)\n",
    "\n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(num_chans_in, num_chans_out, kernel_size=1,padding=0,stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=num_chans_out),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.relu(out)\n",
    "        return out + self.downsample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ResNet 152\n",
    "\n",
    "The same as ResNet 50 but with more blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResNetMLMed152 Class\n",
    "#       - constructs a ResNet152 as described in [2, Table 1].\n",
    "# Input:    Tensor: [Batch,1,Height,Width]\n",
    "# Output:   Tensor: [Batch,3]\n",
    "class ResNetMLMed152(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMLMed152, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size =7, stride =2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2,padding=1)\n",
    "        self.resblocks2 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 64,n_chans_between =64 ,num_chans_out=256,downsample= True),\n",
    "            *(2 * [ResBlockBottleneck(num_chans_in = 256,n_chans_between=64,num_chans_out= 256)]))\n",
    "        self.resblocks3 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 256, n_chans_between=128, num_chans_out= 512, downsample=True, stride=2),\n",
    "            *(7 * [ResBlockBottleneck(num_chans_in = 512,n_chans_between=128,num_chans_out= 512)]))\n",
    "        self.resblocks4 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 512, n_chans_between=256, num_chans_out= 1024,downsample=True, stride=2),\n",
    "            *(35 * [ResBlockBottleneck(num_chans_in = 1024,n_chans_between=256,num_chans_out= 1024)]))\n",
    "        self.resblocks5 = nn.Sequential(\n",
    "            ResBlockBottleneck(num_chans_in = 1024, n_chans_between=512, num_chans_out= 2048,downsample=True, stride=2),\n",
    "            *(2 * [ResBlockBottleneck(num_chans_in = 2048,n_chans_between=512,num_chans_out= 2048)]))\n",
    "        self.avgpool6 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=2048, out_features=3, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv1(x)\n",
    "        out_1 = self.batch_norm1(out_1)\n",
    "        out_1 = self.relu(out_1)\n",
    "        out_1 = self.pool2(out_1)\n",
    "\n",
    "        out_2 = self.resblocks2(out_1)\n",
    "\n",
    "        out_3 = self.resblocks3(out_2)\n",
    "\n",
    "        out_4= self.resblocks4(out_3)\n",
    "\n",
    "        out_5= self.resblocks5(out_4)\n",
    "\n",
    "        out_6 = self.avgpool6(out_5)\n",
    "\n",
    "        out_6= self.fc(torch.flatten(out_6, start_dim=1))\n",
    "\n",
    "        return out_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 126, 126]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 126, 126]             128\n",
      "              ReLU-3         [-1, 64, 126, 126]               0\n",
      "         MaxPool2d-4           [-1, 64, 63, 63]               0\n",
      "            Conv2d-5           [-1, 64, 63, 63]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 63, 63]             128\n",
      "              ReLU-7           [-1, 64, 63, 63]               0\n",
      "            Conv2d-8           [-1, 64, 63, 63]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 63, 63]             128\n",
      "             ReLU-10           [-1, 64, 63, 63]               0\n",
      "           Conv2d-11          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 63, 63]             512\n",
      "             ReLU-13          [-1, 256, 63, 63]               0\n",
      "           Conv2d-14          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 63, 63]             512\n",
      "             ReLU-16          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-17          [-1, 256, 63, 63]               0\n",
      "           Conv2d-18           [-1, 64, 63, 63]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 63, 63]             128\n",
      "             ReLU-20           [-1, 64, 63, 63]               0\n",
      "           Conv2d-21           [-1, 64, 63, 63]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 63, 63]             128\n",
      "             ReLU-23           [-1, 64, 63, 63]               0\n",
      "           Conv2d-24          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 63, 63]             512\n",
      "             ReLU-26          [-1, 256, 63, 63]               0\n",
      "         Identity-27          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-28          [-1, 256, 63, 63]               0\n",
      "           Conv2d-29           [-1, 64, 63, 63]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 63, 63]             128\n",
      "             ReLU-31           [-1, 64, 63, 63]               0\n",
      "           Conv2d-32           [-1, 64, 63, 63]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 63, 63]             128\n",
      "             ReLU-34           [-1, 64, 63, 63]               0\n",
      "           Conv2d-35          [-1, 256, 63, 63]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 63, 63]             512\n",
      "             ReLU-37          [-1, 256, 63, 63]               0\n",
      "         Identity-38          [-1, 256, 63, 63]               0\n",
      "ResBlockBottleneck-39          [-1, 256, 63, 63]               0\n",
      "           Conv2d-40          [-1, 128, 63, 63]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 63, 63]             256\n",
      "             ReLU-42          [-1, 128, 63, 63]               0\n",
      "           Conv2d-43          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 32, 32]             256\n",
      "             ReLU-45          [-1, 128, 32, 32]               0\n",
      "           Conv2d-46          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-52          [-1, 512, 32, 32]               0\n",
      "           Conv2d-53          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 32, 32]             256\n",
      "             ReLU-55          [-1, 128, 32, 32]               0\n",
      "           Conv2d-56          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 32, 32]             256\n",
      "             ReLU-58          [-1, 128, 32, 32]               0\n",
      "           Conv2d-59          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-61          [-1, 512, 32, 32]               0\n",
      "         Identity-62          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-63          [-1, 512, 32, 32]               0\n",
      "           Conv2d-64          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 32, 32]             256\n",
      "             ReLU-66          [-1, 128, 32, 32]               0\n",
      "           Conv2d-67          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 32, 32]             256\n",
      "             ReLU-69          [-1, 128, 32, 32]               0\n",
      "           Conv2d-70          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-72          [-1, 512, 32, 32]               0\n",
      "         Identity-73          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-74          [-1, 512, 32, 32]               0\n",
      "           Conv2d-75          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 32, 32]             256\n",
      "             ReLU-77          [-1, 128, 32, 32]               0\n",
      "           Conv2d-78          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 32, 32]             256\n",
      "             ReLU-80          [-1, 128, 32, 32]               0\n",
      "           Conv2d-81          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-83          [-1, 512, 32, 32]               0\n",
      "         Identity-84          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-85          [-1, 512, 32, 32]               0\n",
      "           Conv2d-86          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-87          [-1, 128, 32, 32]             256\n",
      "             ReLU-88          [-1, 128, 32, 32]               0\n",
      "           Conv2d-89          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-90          [-1, 128, 32, 32]             256\n",
      "             ReLU-91          [-1, 128, 32, 32]               0\n",
      "           Conv2d-92          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-93          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-94          [-1, 512, 32, 32]               0\n",
      "         Identity-95          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-96          [-1, 512, 32, 32]               0\n",
      "           Conv2d-97          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-98          [-1, 128, 32, 32]             256\n",
      "             ReLU-99          [-1, 128, 32, 32]               0\n",
      "          Conv2d-100          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-101          [-1, 128, 32, 32]             256\n",
      "            ReLU-102          [-1, 128, 32, 32]               0\n",
      "          Conv2d-103          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-104          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-105          [-1, 512, 32, 32]               0\n",
      "        Identity-106          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-107          [-1, 512, 32, 32]               0\n",
      "          Conv2d-108          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-109          [-1, 128, 32, 32]             256\n",
      "            ReLU-110          [-1, 128, 32, 32]               0\n",
      "          Conv2d-111          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-112          [-1, 128, 32, 32]             256\n",
      "            ReLU-113          [-1, 128, 32, 32]               0\n",
      "          Conv2d-114          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-115          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-116          [-1, 512, 32, 32]               0\n",
      "        Identity-117          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-118          [-1, 512, 32, 32]               0\n",
      "          Conv2d-119          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-120          [-1, 128, 32, 32]             256\n",
      "            ReLU-121          [-1, 128, 32, 32]               0\n",
      "          Conv2d-122          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-123          [-1, 128, 32, 32]             256\n",
      "            ReLU-124          [-1, 128, 32, 32]               0\n",
      "          Conv2d-125          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-126          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-127          [-1, 512, 32, 32]               0\n",
      "        Identity-128          [-1, 512, 32, 32]               0\n",
      "ResBlockBottleneck-129          [-1, 512, 32, 32]               0\n",
      "          Conv2d-130          [-1, 256, 32, 32]         131,072\n",
      "     BatchNorm2d-131          [-1, 256, 32, 32]             512\n",
      "            ReLU-132          [-1, 256, 32, 32]               0\n",
      "          Conv2d-133          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-134          [-1, 256, 16, 16]             512\n",
      "            ReLU-135          [-1, 256, 16, 16]               0\n",
      "          Conv2d-136         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-137         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-138         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-139         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-140         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-141         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-142         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-143          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 16, 16]             512\n",
      "            ReLU-145          [-1, 256, 16, 16]               0\n",
      "          Conv2d-146          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 16, 16]             512\n",
      "            ReLU-148          [-1, 256, 16, 16]               0\n",
      "          Conv2d-149         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-151         [-1, 1024, 16, 16]               0\n",
      "        Identity-152         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-153         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-154          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-155          [-1, 256, 16, 16]             512\n",
      "            ReLU-156          [-1, 256, 16, 16]               0\n",
      "          Conv2d-157          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 16, 16]             512\n",
      "            ReLU-159          [-1, 256, 16, 16]               0\n",
      "          Conv2d-160         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-162         [-1, 1024, 16, 16]               0\n",
      "        Identity-163         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-164         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-165          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-166          [-1, 256, 16, 16]             512\n",
      "            ReLU-167          [-1, 256, 16, 16]               0\n",
      "          Conv2d-168          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-169          [-1, 256, 16, 16]             512\n",
      "            ReLU-170          [-1, 256, 16, 16]               0\n",
      "          Conv2d-171         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-172         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-173         [-1, 1024, 16, 16]               0\n",
      "        Identity-174         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-175         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-176          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 16, 16]             512\n",
      "            ReLU-178          [-1, 256, 16, 16]               0\n",
      "          Conv2d-179          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 16, 16]             512\n",
      "            ReLU-181          [-1, 256, 16, 16]               0\n",
      "          Conv2d-182         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-184         [-1, 1024, 16, 16]               0\n",
      "        Identity-185         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-186         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-187          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 16, 16]             512\n",
      "            ReLU-189          [-1, 256, 16, 16]               0\n",
      "          Conv2d-190          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 16, 16]             512\n",
      "            ReLU-192          [-1, 256, 16, 16]               0\n",
      "          Conv2d-193         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-195         [-1, 1024, 16, 16]               0\n",
      "        Identity-196         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-197         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-198          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 16, 16]             512\n",
      "            ReLU-200          [-1, 256, 16, 16]               0\n",
      "          Conv2d-201          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-202          [-1, 256, 16, 16]             512\n",
      "            ReLU-203          [-1, 256, 16, 16]               0\n",
      "          Conv2d-204         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-205         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-206         [-1, 1024, 16, 16]               0\n",
      "        Identity-207         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-208         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-209          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-210          [-1, 256, 16, 16]             512\n",
      "            ReLU-211          [-1, 256, 16, 16]               0\n",
      "          Conv2d-212          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-213          [-1, 256, 16, 16]             512\n",
      "            ReLU-214          [-1, 256, 16, 16]               0\n",
      "          Conv2d-215         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-216         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-217         [-1, 1024, 16, 16]               0\n",
      "        Identity-218         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-219         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-220          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 16, 16]             512\n",
      "            ReLU-222          [-1, 256, 16, 16]               0\n",
      "          Conv2d-223          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 16, 16]             512\n",
      "            ReLU-225          [-1, 256, 16, 16]               0\n",
      "          Conv2d-226         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-228         [-1, 1024, 16, 16]               0\n",
      "        Identity-229         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-230         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-231          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 16, 16]             512\n",
      "            ReLU-233          [-1, 256, 16, 16]               0\n",
      "          Conv2d-234          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 16, 16]             512\n",
      "            ReLU-236          [-1, 256, 16, 16]               0\n",
      "          Conv2d-237         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-239         [-1, 1024, 16, 16]               0\n",
      "        Identity-240         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-241         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-242          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-243          [-1, 256, 16, 16]             512\n",
      "            ReLU-244          [-1, 256, 16, 16]               0\n",
      "          Conv2d-245          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 16, 16]             512\n",
      "            ReLU-247          [-1, 256, 16, 16]               0\n",
      "          Conv2d-248         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-249         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-250         [-1, 1024, 16, 16]               0\n",
      "        Identity-251         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-252         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-253          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-254          [-1, 256, 16, 16]             512\n",
      "            ReLU-255          [-1, 256, 16, 16]               0\n",
      "          Conv2d-256          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-257          [-1, 256, 16, 16]             512\n",
      "            ReLU-258          [-1, 256, 16, 16]               0\n",
      "          Conv2d-259         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-260         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-261         [-1, 1024, 16, 16]               0\n",
      "        Identity-262         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-263         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-264          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-265          [-1, 256, 16, 16]             512\n",
      "            ReLU-266          [-1, 256, 16, 16]               0\n",
      "          Conv2d-267          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-268          [-1, 256, 16, 16]             512\n",
      "            ReLU-269          [-1, 256, 16, 16]               0\n",
      "          Conv2d-270         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-271         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-272         [-1, 1024, 16, 16]               0\n",
      "        Identity-273         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-274         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-275          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-276          [-1, 256, 16, 16]             512\n",
      "            ReLU-277          [-1, 256, 16, 16]               0\n",
      "          Conv2d-278          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-279          [-1, 256, 16, 16]             512\n",
      "            ReLU-280          [-1, 256, 16, 16]               0\n",
      "          Conv2d-281         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-282         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-283         [-1, 1024, 16, 16]               0\n",
      "        Identity-284         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-285         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-286          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-287          [-1, 256, 16, 16]             512\n",
      "            ReLU-288          [-1, 256, 16, 16]               0\n",
      "          Conv2d-289          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-290          [-1, 256, 16, 16]             512\n",
      "            ReLU-291          [-1, 256, 16, 16]               0\n",
      "          Conv2d-292         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-293         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-294         [-1, 1024, 16, 16]               0\n",
      "        Identity-295         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-296         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-297          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-298          [-1, 256, 16, 16]             512\n",
      "            ReLU-299          [-1, 256, 16, 16]               0\n",
      "          Conv2d-300          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-301          [-1, 256, 16, 16]             512\n",
      "            ReLU-302          [-1, 256, 16, 16]               0\n",
      "          Conv2d-303         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-304         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-305         [-1, 1024, 16, 16]               0\n",
      "        Identity-306         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-307         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-308          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-309          [-1, 256, 16, 16]             512\n",
      "            ReLU-310          [-1, 256, 16, 16]               0\n",
      "          Conv2d-311          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-312          [-1, 256, 16, 16]             512\n",
      "            ReLU-313          [-1, 256, 16, 16]               0\n",
      "          Conv2d-314         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-316         [-1, 1024, 16, 16]               0\n",
      "        Identity-317         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-318         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-319          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-320          [-1, 256, 16, 16]             512\n",
      "            ReLU-321          [-1, 256, 16, 16]               0\n",
      "          Conv2d-322          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-323          [-1, 256, 16, 16]             512\n",
      "            ReLU-324          [-1, 256, 16, 16]               0\n",
      "          Conv2d-325         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-326         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-327         [-1, 1024, 16, 16]               0\n",
      "        Identity-328         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-329         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-330          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-331          [-1, 256, 16, 16]             512\n",
      "            ReLU-332          [-1, 256, 16, 16]               0\n",
      "          Conv2d-333          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-334          [-1, 256, 16, 16]             512\n",
      "            ReLU-335          [-1, 256, 16, 16]               0\n",
      "          Conv2d-336         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-337         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-338         [-1, 1024, 16, 16]               0\n",
      "        Identity-339         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-340         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-341          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 16, 16]             512\n",
      "            ReLU-343          [-1, 256, 16, 16]               0\n",
      "          Conv2d-344          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 16, 16]             512\n",
      "            ReLU-346          [-1, 256, 16, 16]               0\n",
      "          Conv2d-347         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-349         [-1, 1024, 16, 16]               0\n",
      "        Identity-350         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-351         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-352          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-353          [-1, 256, 16, 16]             512\n",
      "            ReLU-354          [-1, 256, 16, 16]               0\n",
      "          Conv2d-355          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-356          [-1, 256, 16, 16]             512\n",
      "            ReLU-357          [-1, 256, 16, 16]               0\n",
      "          Conv2d-358         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-359         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-360         [-1, 1024, 16, 16]               0\n",
      "        Identity-361         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-362         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-363          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-364          [-1, 256, 16, 16]             512\n",
      "            ReLU-365          [-1, 256, 16, 16]               0\n",
      "          Conv2d-366          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-367          [-1, 256, 16, 16]             512\n",
      "            ReLU-368          [-1, 256, 16, 16]               0\n",
      "          Conv2d-369         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-370         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-371         [-1, 1024, 16, 16]               0\n",
      "        Identity-372         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-373         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-374          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-375          [-1, 256, 16, 16]             512\n",
      "            ReLU-376          [-1, 256, 16, 16]               0\n",
      "          Conv2d-377          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-378          [-1, 256, 16, 16]             512\n",
      "            ReLU-379          [-1, 256, 16, 16]               0\n",
      "          Conv2d-380         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-381         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-382         [-1, 1024, 16, 16]               0\n",
      "        Identity-383         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-384         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-385          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-386          [-1, 256, 16, 16]             512\n",
      "            ReLU-387          [-1, 256, 16, 16]               0\n",
      "          Conv2d-388          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-389          [-1, 256, 16, 16]             512\n",
      "            ReLU-390          [-1, 256, 16, 16]               0\n",
      "          Conv2d-391         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-392         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-393         [-1, 1024, 16, 16]               0\n",
      "        Identity-394         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-395         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-396          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-397          [-1, 256, 16, 16]             512\n",
      "            ReLU-398          [-1, 256, 16, 16]               0\n",
      "          Conv2d-399          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-400          [-1, 256, 16, 16]             512\n",
      "            ReLU-401          [-1, 256, 16, 16]               0\n",
      "          Conv2d-402         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-403         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-404         [-1, 1024, 16, 16]               0\n",
      "        Identity-405         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-406         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-407          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-408          [-1, 256, 16, 16]             512\n",
      "            ReLU-409          [-1, 256, 16, 16]               0\n",
      "          Conv2d-410          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-411          [-1, 256, 16, 16]             512\n",
      "            ReLU-412          [-1, 256, 16, 16]               0\n",
      "          Conv2d-413         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-414         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-415         [-1, 1024, 16, 16]               0\n",
      "        Identity-416         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-417         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-418          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-419          [-1, 256, 16, 16]             512\n",
      "            ReLU-420          [-1, 256, 16, 16]               0\n",
      "          Conv2d-421          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-422          [-1, 256, 16, 16]             512\n",
      "            ReLU-423          [-1, 256, 16, 16]               0\n",
      "          Conv2d-424         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-425         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-426         [-1, 1024, 16, 16]               0\n",
      "        Identity-427         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-428         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-429          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-430          [-1, 256, 16, 16]             512\n",
      "            ReLU-431          [-1, 256, 16, 16]               0\n",
      "          Conv2d-432          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-433          [-1, 256, 16, 16]             512\n",
      "            ReLU-434          [-1, 256, 16, 16]               0\n",
      "          Conv2d-435         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-436         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-437         [-1, 1024, 16, 16]               0\n",
      "        Identity-438         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-439         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-440          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-441          [-1, 256, 16, 16]             512\n",
      "            ReLU-442          [-1, 256, 16, 16]               0\n",
      "          Conv2d-443          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-444          [-1, 256, 16, 16]             512\n",
      "            ReLU-445          [-1, 256, 16, 16]               0\n",
      "          Conv2d-446         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-447         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-448         [-1, 1024, 16, 16]               0\n",
      "        Identity-449         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-450         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-451          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 16, 16]             512\n",
      "            ReLU-453          [-1, 256, 16, 16]               0\n",
      "          Conv2d-454          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 16, 16]             512\n",
      "            ReLU-456          [-1, 256, 16, 16]               0\n",
      "          Conv2d-457         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-459         [-1, 1024, 16, 16]               0\n",
      "        Identity-460         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-461         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-462          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-463          [-1, 256, 16, 16]             512\n",
      "            ReLU-464          [-1, 256, 16, 16]               0\n",
      "          Conv2d-465          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-466          [-1, 256, 16, 16]             512\n",
      "            ReLU-467          [-1, 256, 16, 16]               0\n",
      "          Conv2d-468         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-469         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-470         [-1, 1024, 16, 16]               0\n",
      "        Identity-471         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-472         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-473          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-474          [-1, 256, 16, 16]             512\n",
      "            ReLU-475          [-1, 256, 16, 16]               0\n",
      "          Conv2d-476          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-477          [-1, 256, 16, 16]             512\n",
      "            ReLU-478          [-1, 256, 16, 16]               0\n",
      "          Conv2d-479         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-480         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-481         [-1, 1024, 16, 16]               0\n",
      "        Identity-482         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-483         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-484          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-485          [-1, 256, 16, 16]             512\n",
      "            ReLU-486          [-1, 256, 16, 16]               0\n",
      "          Conv2d-487          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-488          [-1, 256, 16, 16]             512\n",
      "            ReLU-489          [-1, 256, 16, 16]               0\n",
      "          Conv2d-490         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-491         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-492         [-1, 1024, 16, 16]               0\n",
      "        Identity-493         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-494         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-495          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-496          [-1, 256, 16, 16]             512\n",
      "            ReLU-497          [-1, 256, 16, 16]               0\n",
      "          Conv2d-498          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-499          [-1, 256, 16, 16]             512\n",
      "            ReLU-500          [-1, 256, 16, 16]               0\n",
      "          Conv2d-501         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-502         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-503         [-1, 1024, 16, 16]               0\n",
      "        Identity-504         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-505         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-506          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-507          [-1, 256, 16, 16]             512\n",
      "            ReLU-508          [-1, 256, 16, 16]               0\n",
      "          Conv2d-509          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-510          [-1, 256, 16, 16]             512\n",
      "            ReLU-511          [-1, 256, 16, 16]               0\n",
      "          Conv2d-512         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-513         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-514         [-1, 1024, 16, 16]               0\n",
      "        Identity-515         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-516         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-517          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-518          [-1, 256, 16, 16]             512\n",
      "            ReLU-519          [-1, 256, 16, 16]               0\n",
      "          Conv2d-520          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-521          [-1, 256, 16, 16]             512\n",
      "            ReLU-522          [-1, 256, 16, 16]               0\n",
      "          Conv2d-523         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-524         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-525         [-1, 1024, 16, 16]               0\n",
      "        Identity-526         [-1, 1024, 16, 16]               0\n",
      "ResBlockBottleneck-527         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-528          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-529          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-530          [-1, 512, 16, 16]               0\n",
      "          Conv2d-531            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-532            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-533            [-1, 512, 8, 8]               0\n",
      "          Conv2d-534           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-535           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-536           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-537           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-538           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-539           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-540           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-541            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-542            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-543            [-1, 512, 8, 8]               0\n",
      "          Conv2d-544            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-545            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-546            [-1, 512, 8, 8]               0\n",
      "          Conv2d-547           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-548           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-549           [-1, 2048, 8, 8]               0\n",
      "        Identity-550           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-551           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-552            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-553            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-554            [-1, 512, 8, 8]               0\n",
      "          Conv2d-555            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-556            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-557            [-1, 512, 8, 8]               0\n",
      "          Conv2d-558           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-559           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-560           [-1, 2048, 8, 8]               0\n",
      "        Identity-561           [-1, 2048, 8, 8]               0\n",
      "ResBlockBottleneck-562           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-563           [-1, 2048, 1, 1]               0\n",
      "          Linear-564                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 58,143,747\n",
      "Trainable params: 58,143,747\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 916.75\n",
      "Params size (MB): 221.80\n",
      "Estimated Total Size (MB): 1138.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMLMed152()\n",
    "summary(model, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (data, targets) in enumerate(dl):\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    if step ==1:\n",
    "        break\n",
    "model = model.to(device)\n",
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop_conf_matr(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    ds = ds,\n",
    "    dl = dl,\n",
    "    batch_size = batch_size,\n",
    "    run_name = run_name,\n",
    "    device = device,\n",
    "    time_me=True,\n",
    "    time=time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5555b6f2b0077a97828fbbfe12cb97727895c9c472121c1b71224aa97370345d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
